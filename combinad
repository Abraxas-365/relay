package scheduler

import (
	"context"
	"time"

	"github.com/Abraxas-365/relay/engine"
	"github.com/Abraxas-365/relay/pkg/kernel"
	"github.com/google/uuid"
	"github.com/robfig/cron/v3"
)

type ScheduleService struct {
	scheduleRepo engine.WorkflowScheduleRepository
	workflowRepo engine.WorkflowRepository
	cronParser   cron.Parser
}

func NewScheduleService(
	scheduleRepo engine.WorkflowScheduleRepository,
	workflowRepo engine.WorkflowRepository,
) *ScheduleService {
	return &ScheduleService{
		scheduleRepo: scheduleRepo,
		workflowRepo: workflowRepo,
		cronParser:   cron.NewParser(cron.Minute | cron.Hour | cron.Dom | cron.Month | cron.Dow),
	}
}

// CreateCronSchedule creates a cron-based schedule
func (s *ScheduleService) CreateCronSchedule(
	ctx context.Context,
	tenantID kernel.TenantID,
	workflowID kernel.WorkflowID,
	cronExpression string,
	timezone string,
) (*engine.WorkflowSchedule, error) {
	// Validate workflow exists
	workflow, err := s.workflowRepo.FindByID(ctx, workflowID)
	if err != nil {
		return nil, engine.ErrWorkflowNotFound().
			WithDetail("workflow_id", workflowID.String())
	}

	if workflow.TenantID != tenantID {
		return nil, engine.ErrWorkflowNotFound().
			WithDetail("workflow_id", workflowID.String()).
			WithDetail("reason", "workflow does not belong to tenant")
	}

	// Validate cron expression
	_, err = s.cronParser.Parse(cronExpression)
	if err != nil {
		return nil, engine.ErrInvalidCronExpression().
			WithDetail("cron_expression", cronExpression).
			WithCause(err)
	}

	// Check if too many schedules exist
	count, err := s.scheduleRepo.CountByWorkflow(ctx, workflowID)
	if err != nil {
		return nil, err
	}
	if count >= 10 { // Max 10 schedules per workflow
		return nil, engine.ErrTooManySchedules().
			WithDetail("workflow_id", workflowID.String()).
			WithDetail("current_count", count)
	}

	// Calculate first run
	loc, err := time.LoadLocation(timezone)
	if err != nil {
		loc = time.UTC
	}

	cronSchedule, _ := s.cronParser.Parse(cronExpression)
	nextRun := cronSchedule.Next(time.Now().In(loc))

	schedule := &engine.WorkflowSchedule{
		ID:             uuid.New().String(),
		TenantID:       tenantID,
		WorkflowID:     workflowID,
		ScheduleType:   engine.ScheduleTypeCron,
		CronExpression: &cronExpression,
		IsActive:       true,
		NextRunAt:      &nextRun,
		Timezone:       timezone,
		CreatedAt:      time.Now(),
		UpdatedAt:      time.Now(),
	}

	if err := s.scheduleRepo.Save(ctx, *schedule); err != nil {
		return nil, err
	}

	return schedule, nil
}

// CreateIntervalSchedule creates an interval-based schedule
func (s *ScheduleService) CreateIntervalSchedule(
	ctx context.Context,
	tenantID kernel.TenantID,
	workflowID kernel.WorkflowID,
	intervalSeconds int,
) (*engine.WorkflowSchedule, error) {
	// Validate workflow exists
	workflow, err := s.workflowRepo.FindByID(ctx, workflowID)
	if err != nil {
		return nil, engine.ErrWorkflowNotFound().
			WithDetail("workflow_id", workflowID.String())
	}

	if workflow.TenantID != tenantID {
		return nil, engine.ErrWorkflowNotFound().
			WithDetail("workflow_id", workflowID.String()).
			WithDetail("reason", "workflow does not belong to tenant")
	}

	// Validate interval
	if intervalSeconds < 60 {
		return nil, engine.ErrInvalidInterval().
			WithDetail("interval_seconds", intervalSeconds).
			WithDetail("reason", "minimum interval is 60 seconds")
	}

	if intervalSeconds > 86400*7 { // Max 7 days
		return nil, engine.ErrInvalidInterval().
			WithDetail("interval_seconds", intervalSeconds).
			WithDetail("reason", "maximum interval is 7 days")
	}

	// Check if too many schedules exist
	count, err := s.scheduleRepo.CountByWorkflow(ctx, workflowID)
	if err != nil {
		return nil, err
	}
	if count >= 10 {
		return nil, engine.ErrTooManySchedules().
			WithDetail("workflow_id", workflowID.String()).
			WithDetail("current_count", count)
	}

	// Calculate first run
	nextRun := time.Now().Add(time.Duration(intervalSeconds) * time.Second)

	schedule := &engine.WorkflowSchedule{
		ID:              uuid.New().String(),
		TenantID:        tenantID,
		WorkflowID:      workflowID,
		ScheduleType:    engine.ScheduleTypeInterval,
		IntervalSeconds: &intervalSeconds,
		IsActive:        true,
		NextRunAt:       &nextRun,
		Timezone:        "UTC",
		CreatedAt:       time.Now(),
		UpdatedAt:       time.Now(),
	}

	if err := s.scheduleRepo.Save(ctx, *schedule); err != nil {
		return nil, err
	}

	return schedule, nil
}

// CreateOnceSchedule creates a one-time schedule
func (s *ScheduleService) CreateOnceSchedule(
	ctx context.Context,
	tenantID kernel.TenantID,
	workflowID kernel.WorkflowID,
	scheduledAt time.Time,
) (*engine.WorkflowSchedule, error) {
	// Validate workflow exists
	workflow, err := s.workflowRepo.FindByID(ctx, workflowID)
	if err != nil {
		return nil, engine.ErrWorkflowNotFound().
			WithDetail("workflow_id", workflowID.String())
	}

	if workflow.TenantID != tenantID {
		return nil, engine.ErrWorkflowNotFound().
			WithDetail("workflow_id", workflowID.String()).
			WithDetail("reason", "workflow does not belong to tenant")
	}

	// Validate scheduled time is in the future
	if scheduledAt.Before(time.Now()) {
		return nil, engine.ErrScheduleInPast().
			WithDetail("scheduled_at", scheduledAt).
			WithDetail("current_time", time.Now())
	}

	schedule := &engine.WorkflowSchedule{
		ID:           uuid.New().String(),
		TenantID:     tenantID,
		WorkflowID:   workflowID,
		ScheduleType: engine.ScheduleTypeOnce,
		ScheduledAt:  &scheduledAt,
		IsActive:     true,
		NextRunAt:    &scheduledAt,
		Timezone:     "UTC",
		CreatedAt:    time.Now(),
		UpdatedAt:    time.Now(),
	}

	if err := s.scheduleRepo.Save(ctx, *schedule); err != nil {
		return nil, err
	}

	return schedule, nil
}

// UpdateSchedule updates an existing schedule
func (s *ScheduleService) UpdateSchedule(
	ctx context.Context,
	scheduleID string,
	tenantID kernel.TenantID,
	updateFn func(*engine.WorkflowSchedule) error,
) (*engine.WorkflowSchedule, error) {
	// Get existing schedule
	schedule, err := s.scheduleRepo.FindByID(ctx, scheduleID)
	if err != nil {
		return nil, engine.ErrScheduleNotFound().
			WithDetail("schedule_id", scheduleID)
	}

	// Verify tenant ownership
	if schedule.TenantID != tenantID {
		return nil, engine.ErrScheduleNotFound().
			WithDetail("schedule_id", scheduleID).
			WithDetail("reason", "schedule does not belong to tenant")
	}

	// Apply update
	if err := updateFn(schedule); err != nil {
		return nil, err
	}

	// Recalculate next run if needed
	if schedule.IsActive {
		nextRun, err := s.calculateNextRun(schedule, time.Now())
		if err != nil {
			return nil, engine.ErrInvalidScheduleConfig().
				WithDetail("schedule_id", scheduleID).
				WithCause(err)
		}
		schedule.NextRunAt = nextRun
	}

	// Save changes
	if err := s.scheduleRepo.Update(ctx, *schedule); err != nil {
		return nil, err
	}

	return schedule, nil
}

// ActivateSchedule activates a schedule
func (s *ScheduleService) ActivateSchedule(
	ctx context.Context,
	scheduleID string,
	tenantID kernel.TenantID,
) error {
	_, err := s.UpdateSchedule(ctx, scheduleID, tenantID, func(schedule *engine.WorkflowSchedule) error {
		schedule.IsActive = true
		return nil
	})
	return err
}

// DeactivateSchedule deactivates a schedule
func (s *ScheduleService) DeactivateSchedule(
	ctx context.Context,
	scheduleID string,
	tenantID kernel.TenantID,
) error {
	_, err := s.UpdateSchedule(ctx, scheduleID, tenantID, func(schedule *engine.WorkflowSchedule) error {
		schedule.IsActive = false
		schedule.NextRunAt = nil
		return nil
	})
	return err
}

// DeleteSchedule deletes a schedule
func (s *ScheduleService) DeleteSchedule(
	ctx context.Context,
	scheduleID string,
	tenantID kernel.TenantID,
) error {
	// Verify ownership before deleting
	schedule, err := s.scheduleRepo.FindByID(ctx, scheduleID)
	if err != nil {
		return engine.ErrScheduleNotFound().
			WithDetail("schedule_id", scheduleID)
	}

	if schedule.TenantID != tenantID {
		return engine.ErrScheduleNotFound().
			WithDetail("schedule_id", scheduleID).
			WithDetail("reason", "schedule does not belong to tenant")
	}

	return s.scheduleRepo.Delete(ctx, scheduleID)
}

// calculateNextRun calculates the next execution time
func (s *ScheduleService) calculateNextRun(schedule *engine.WorkflowSchedule, after time.Time) (*time.Time, error) {
	switch schedule.ScheduleType {
	case engine.ScheduleTypeCron:
		if schedule.CronExpression == nil {
			return nil, engine.ErrInvalidScheduleConfig().
				WithDetail("reason", "cron expression is nil")
		}

		cronSchedule, err := s.cronParser.Parse(*schedule.CronExpression)
		if err != nil {
			return nil, engine.ErrInvalidCronExpression().
				WithDetail("cron_expression", *schedule.CronExpression).
				WithCause(err)
		}

		loc, err := time.LoadLocation(schedule.Timezone)
		if err != nil {
			loc = time.UTC
		}

		next := cronSchedule.Next(after.In(loc))
		return &next, nil

	case engine.ScheduleTypeInterval:
		if schedule.IntervalSeconds == nil {
			return nil, engine.ErrInvalidScheduleConfig().
				WithDetail("reason", "interval_seconds is nil")
		}

		interval := time.Duration(*schedule.IntervalSeconds) * time.Second
		next := after.Add(interval)
		return &next, nil

	case engine.ScheduleTypeOnce:
		return nil, nil // One-time schedules don't repeat

	default:
		return nil, engine.ErrInvalidScheduleConfig().
			WithDetail("schedule_type", string(schedule.ScheduleType))
	}
}

package scheduler

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/Abraxas-365/relay/engine"
	"github.com/Abraxas-365/relay/engine/triggerhandler"
	"github.com/robfig/cron/v3"
)

type WorkflowScheduler struct {
	scheduleRepo   engine.WorkflowScheduleRepository
	triggerHandler *triggerhandler.TriggerHandler
	cronParser     cron.Parser
	stopChan       chan struct{}
	running        bool
}

func NewWorkflowScheduler(
	scheduleRepo engine.WorkflowScheduleRepository,
	triggerHandler *triggerhandler.TriggerHandler,
) *WorkflowScheduler {
	return &WorkflowScheduler{
		scheduleRepo:   scheduleRepo,
		triggerHandler: triggerHandler,
		cronParser:     cron.NewParser(cron.Minute | cron.Hour | cron.Dom | cron.Month | cron.Dow),
		stopChan:       make(chan struct{}),
	}
}

// Start starts the scheduler
func (s *WorkflowScheduler) Start(ctx context.Context) {
	if s.running {
		log.Println("‚ö†Ô∏è  Scheduler already running")
		return
	}

	s.running = true
	log.Println("‚è∞ Starting workflow scheduler...")

	// Run immediately on start
	go s.processDueSchedules(ctx)

	// Then run every minute
	ticker := time.NewTicker(1 * time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			log.Println("‚èπÔ∏è  Scheduler stopped (context done)")
			return
		case <-s.stopChan:
			log.Println("‚èπÔ∏è  Scheduler stopped")
			return
		case <-ticker.C:
			s.processDueSchedules(ctx)
		}
	}
}

// Stop stops the scheduler
func (s *WorkflowScheduler) Stop() {
	if !s.running {
		return
	}
	close(s.stopChan)
	s.running = false
}

// processDueSchedules checks and executes due schedules
func (s *WorkflowScheduler) processDueSchedules(ctx context.Context) {
	now := time.Now()

	// Get all active schedules that are due
	schedules, err := s.scheduleRepo.FindDue(ctx, now)
	if err != nil {
		log.Printf("‚ùå Failed to fetch due schedules: %v", err)
		return
	}

	if len(schedules) == 0 {
		return
	}

	log.Printf("‚è∞ Found %d due schedule(s)", len(schedules))

	for _, schedule := range schedules {
		// Execute in goroutine to not block
		go s.executeSchedule(ctx, schedule)
	}
}

// executeSchedule executes a single schedule
func (s *WorkflowScheduler) executeSchedule(ctx context.Context, schedule *engine.WorkflowSchedule) {
	log.Printf("‚ñ∂Ô∏è  Executing schedule: %s (workflow: %s)", schedule.ID, schedule.WorkflowID)

	// Prepare trigger data
	triggerData := map[string]any{
		"schedule_id":    schedule.ID,
		"schedule_type":  schedule.ScheduleType,
		"execution_time": time.Now().Unix(),
		"run_count":      schedule.RunCount + 1,
	}

	if schedule.CronExpression != nil {
		triggerData["cron_expression"] = *schedule.CronExpression
	}
	if schedule.IntervalSeconds != nil {
		triggerData["interval_seconds"] = *schedule.IntervalSeconds
	}

	// Trigger workflow
	err := s.triggerHandler.HandleScheduleTrigger(
		ctx,
		schedule.TenantID,
		schedule.ID,
		triggerData,
	)

	if err != nil {
		log.Printf("‚ùå Failed to trigger workflow: %v", err)
		return
	}

	// Update schedule
	now := time.Now()
	schedule.MarkExecuted(now)

	// Calculate next run time
	nextRun, err := s.calculateNextRun(schedule, now)
	if err != nil {
		log.Printf("‚ö†Ô∏è  Failed to calculate next run: %v", err)
	} else {
		schedule.NextRunAt = nextRun
	}

	// Save updated schedule
	if err := s.scheduleRepo.Update(ctx, *schedule); err != nil {
		log.Printf("‚ùå Failed to update schedule: %v", err)
	}

	log.Printf("‚úÖ Schedule executed successfully: %s", schedule.ID)
}

// calculateNextRun calculates the next execution time
func (s *WorkflowScheduler) calculateNextRun(schedule *engine.WorkflowSchedule, after time.Time) (*time.Time, error) {
	switch schedule.ScheduleType {
	case engine.ScheduleTypeCron:
		return s.calculateCronNextRun(schedule, after)
	case engine.ScheduleTypeInterval:
		return s.calculateIntervalNextRun(schedule, after)
	case engine.ScheduleTypeOnce:
		return nil, nil // One-time schedules don't repeat
	default:
		return nil, fmt.Errorf("unknown schedule type: %s", schedule.ScheduleType)
	}
}

// calculateCronNextRun calculates next run for cron schedules
func (s *WorkflowScheduler) calculateCronNextRun(schedule *engine.WorkflowSchedule, after time.Time) (*time.Time, error) {
	if schedule.CronExpression == nil {
		return nil, fmt.Errorf("cron expression is nil")
	}

	cronSchedule, err := s.cronParser.Parse(*schedule.CronExpression)
	if err != nil {
		return nil, fmt.Errorf("invalid cron expression: %w", err)
	}

	// Get timezone
	loc, err := time.LoadLocation(schedule.Timezone)
	if err != nil {
		loc = time.UTC
	}

	next := cronSchedule.Next(after.In(loc))
	return &next, nil
}

// calculateIntervalNextRun calculates next run for interval schedules
func (s *WorkflowScheduler) calculateIntervalNextRun(schedule *engine.WorkflowSchedule, after time.Time) (*time.Time, error) {
	if schedule.IntervalSeconds == nil {
		return nil, fmt.Errorf("interval_seconds is nil")
	}

	interval := time.Duration(*schedule.IntervalSeconds) * time.Second
	next := after.Add(interval)
	return &next, nil
}
package node

import (
	"context"
	"fmt"
	"time"

	"github.com/Abraxas-365/relay/engine"
)

type DelayExecutor struct {
	scheduler engine.DelayScheduler
}

func NewDelayExecutor(scheduler engine.DelayScheduler) *DelayExecutor {
	return &DelayExecutor{
		scheduler: scheduler,
	}
}

func (e *DelayExecutor) Execute(
	ctx context.Context,
	node engine.WorkflowNode,
	input map[string]any,
) (*engine.NodeResult, error) {
	result := &engine.NodeResult{
		NodeID:    node.ID,
		NodeName:  node.Name,
		Success:   true,
		Output:    make(map[string]any),
		Timestamp: time.Now(),
	}

	duration, err := e.parseDuration(node.Config)
	if err != nil {
		result.Success = false
		result.Error = err.Error()
		return result, err
	}

	if duration < 0 {
		err := fmt.Errorf("duration cannot be negative")
		result.Success = false
		result.Error = err.Error()
		return result, err
	}

	maxDelay := 24 * time.Hour
	if duration > maxDelay {
		err := fmt.Errorf("delay exceeds maximum allowed (%v)", maxDelay)
		result.Success = false
		result.Error = err.Error()
		return result, err
	}

	if !e.scheduler.ShouldUseAsync(duration) {
		return e.executeSyncDelay(ctx, duration, result)
	}

	return e.executeAsyncDelay(ctx, node, duration, input, result)
}

func (e *DelayExecutor) executeSyncDelay(
	ctx context.Context,
	duration time.Duration,
	result *engine.NodeResult,
) (*engine.NodeResult, error) {
	startTime := time.Now()
	timer := time.NewTimer(duration)
	defer timer.Stop()

	select {
	case <-timer.C:
		actualDuration := time.Since(startTime)
		result.Output["delayed_ms"] = actualDuration.Milliseconds()
		result.Output["requested_ms"] = duration.Milliseconds()
		result.Output["mode"] = "sync"
		result.Output["completed"] = true
		return result, nil
	case <-ctx.Done():
		result.Success = false
		result.Error = "delay cancelled"
		result.Output["completed"] = false
		result.Output["mode"] = "sync"
		return result, ctx.Err()
	}
}

func (e *DelayExecutor) executeAsyncDelay(
	ctx context.Context,
	node engine.WorkflowNode,
	duration time.Duration,
	input map[string]any,
	result *engine.NodeResult,
) (*engine.NodeResult, error) {
	continuation := &engine.WorkflowContinuation{
		WorkflowID:  extractString(input, "workflow_id"),
		TenantID:    extractString(input, "tenant_id"),
		NodeID:      node.ID,
		NextNodeID:  node.OnSuccess,
		NodeContext: input,
	}

	if err := e.scheduler.Schedule(ctx, continuation, duration); err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("failed to schedule delay: %v", err)
		return result, err
	}

	result.Output["delayed_ms"] = duration.Milliseconds()
	result.Output["mode"] = "async"
	result.Output["scheduled"] = true
	result.Output["continuation_id"] = continuation.ID
	result.Output["execute_at"] = continuation.ScheduledFor.Format(time.RFC3339)
	result.Output["__workflow_paused"] = true // Signal to pause workflow
	result.Success = true

	return result, nil
}

func (e *DelayExecutor) parseDuration(config map[string]any) (time.Duration, error) {
	if durationMs, ok := config["duration_ms"].(float64); ok {
		return time.Duration(durationMs) * time.Millisecond, nil
	}

	if durationStr, ok := config["duration"].(string); ok {
		return time.ParseDuration(durationStr)
	}

	if durationSec, ok := config["duration_seconds"].(float64); ok {
		return time.Duration(durationSec * float64(time.Second)), nil
	}

	return 0, fmt.Errorf("duration not found (try: duration_ms, duration, or duration_seconds)")
}

func (e *DelayExecutor) SupportsType(nodeType engine.NodeType) bool {
	return nodeType == engine.NodeTypeDelay
}

func (e *DelayExecutor) ValidateConfig(config map[string]any) error {
	_, err := e.parseDuration(config)
	return err
}

func extractString(m map[string]any, key string) string {
	if val, ok := m[key]; ok {
		if str, ok := val.(string); ok {
			return str
		}
		if nested, ok := val.(map[string]any); ok {
			if id, ok := nested["id"].(string); ok {
				return id
			}
		}
	}
	return ""
}
package node

import "github.com/Abraxas-365/craftable/ptrx"

// ============================================================================
// Schema Types
// ============================================================================

type NodeConfigSchema struct {
	NodeType    string        `json:"node_type"`
	DisplayName string        `json:"display_name"`
	Description string        `json:"description"`
	Icon        string        `json:"icon,omitempty"`
	Category    string        `json:"category"`
	Fields      []FieldSchema `json:"fields"`
}

type FieldSchema struct {
	Name         string        `json:"name"`
	Label        string        `json:"label"`
	Type         FieldType     `json:"type"`
	Required     bool          `json:"required"`
	DefaultValue any           `json:"default_value,omitempty"`
	Description  string        `json:"description"`
	Placeholder  string        `json:"placeholder,omitempty"`
	Options      []FieldOption `json:"options,omitempty"` // For select/radio
	Validation   *Validation   `json:"validation,omitempty"`
	DependsOn    *Dependency   `json:"depends_on,omitempty"` // Conditional fields
}

type FieldType string

const (
	FieldTypeString   FieldType = "string"
	FieldTypeNumber   FieldType = "number"
	FieldTypeBoolean  FieldType = "boolean"
	FieldTypeSelect   FieldType = "select"
	FieldTypeTextarea FieldType = "textarea"
	FieldTypeJSON     FieldType = "json"
	FieldTypeURL      FieldType = "url"
	FieldTypeEmail    FieldType = "email"
	FieldTypePhone    FieldType = "phone"
	FieldTypeArray    FieldType = "array"
	FieldTypeKeyValue FieldType = "key_value" // For maps like headers
)

type FieldOption struct {
	Value       string `json:"value"`
	Label       string `json:"label"`
	Description string `json:"description,omitempty"`
}

type Validation struct {
	Min     *float32 `json:"min,omitempty"`
	Max     *float32 `json:"max,omitempty"`
	Pattern string   `json:"pattern,omitempty"` // Regex
	Message string   `json:"message,omitempty"`
}

type Dependency struct {
	Field string `json:"field"`
	Value any    `json:"value"`
}

// ============================================================================
// All Node Schemas
// ============================================================================

func GetAllNodeSchemas() map[string]NodeConfigSchema {
	return map[string]NodeConfigSchema{
		"AI_AGENT":     GetAIAgentSchema(),
		"HTTP":         GetHTTPSchema(),
		"SEND_MESSAGE": GetSendMessageSchema(),
		"TRANSFORM":    GetTransformSchema(),
		"CONDITION":    GetConditionSchema(),
		"SWITCH":       GetSwitchSchema(),
		"LOOP":         GetLoopSchema(),
		"VALIDATE":     GetValidateSchema(),
		"DELAY":        GetDelaySchema(),
		"ACTION":       GetActionSchema(),
	}
}

// ============================================================================
// 1. AI_AGENT Schema
// ============================================================================

func GetAIAgentSchema() NodeConfigSchema {
	return NodeConfigSchema{
		NodeType:    "AI_AGENT",
		DisplayName: "AI Agent",
		Description: "Execute AI tasks with LLM models (OpenAI, Claude, etc.)",
		Icon:        "ü§ñ",
		Category:    "AI",
		Fields: []FieldSchema{
			{
				Name:         "provider",
				Label:        "Provider",
				Type:         FieldTypeSelect,
				Required:     true,
				Description:  "AI provider",
				DefaultValue: "openai",
				Options: []FieldOption{
					{Value: "openai", Label: "OpenAI", Description: "GPT models"},
					{Value: "anthropic", Label: "Anthropic", Description: "Claude models"},
					{Value: "google", Label: "Google", Description: "Gemini models"},
				},
			},
			{
				Name:         "model",
				Label:        "Model",
				Type:         FieldTypeSelect,
				Required:     true,
				Description:  "AI model to use",
				DefaultValue: "gpt-4",
				Options: []FieldOption{
					{Value: "gpt-4", Label: "GPT-4"},
					{Value: "gpt-4-turbo", Label: "GPT-4 Turbo"},
					{Value: "gpt-3.5-turbo", Label: "GPT-3.5 Turbo"},
					{Value: "claude-3-opus", Label: "Claude 3 Opus"},
					{Value: "claude-3-sonnet", Label: "Claude 3 Sonnet"},
				},
			},
			{
				Name:        "system_prompt",
				Label:       "System Prompt",
				Type:        FieldTypeTextarea,
				Required:    true,
				Description: "Instructions for the AI assistant",
				Placeholder: "You are a helpful assistant that...",
			},
			{
				Name:        "prompt",
				Label:       "User Prompt",
				Type:        FieldTypeTextarea,
				Required:    false,
				Description: "User message (if not from trigger). Supports {{variable}} syntax",
				Placeholder: "Generate a summary of {{trigger.body.text}}",
			},
			{
				Name:         "temperature",
				Label:        "Temperature",
				Type:         FieldTypeNumber,
				Required:     false,
				DefaultValue: 0.7,
				Description:  "Creativity level (0-2). Higher = more creative",
				Validation: &Validation{
					Min:     ptrx.Float32(0),
					Max:     ptrx.Float32(2),
					Message: "Temperature must be between 0 and 2",
				},
			},
			{
				Name:         "max_tokens",
				Label:        "Max Tokens",
				Type:         FieldTypeNumber,
				Required:     false,
				DefaultValue: 1000,
				Description:  "Maximum response length",
				Validation: &Validation{
					Min:     ptrx.Float32(1),
					Max:     ptrx.Float32(8000),
					Message: "Max tokens must be between 1 and 8000",
				},
			},
			{
				Name:         "use_memory",
				Label:        "Use Conversation Memory",
				Type:         FieldTypeBoolean,
				Required:     false,
				DefaultValue: false,
				Description:  "Enable persistent conversation memory",
			},
			{
				Name:         "max_auto_iterations",
				Label:        "Max Auto Iterations",
				Type:         FieldTypeNumber,
				Required:     false,
				DefaultValue: 3,
				Description:  "Max auto-iterations for agent",
				DependsOn: &Dependency{
					Field: "use_memory",
					Value: true,
				},
			},
		},
	}
}

// ============================================================================
// 2. HTTP Schema
// ============================================================================

func GetHTTPSchema() NodeConfigSchema {
	return NodeConfigSchema{
		NodeType:    "HTTP",
		DisplayName: "HTTP Request",
		Description: "Make HTTP/REST API calls",
		Icon:        "üåê",
		Category:    "Integration",
		Fields: []FieldSchema{
			{
				Name:         "method",
				Label:        "Method",
				Type:         FieldTypeSelect,
				Required:     true,
				DefaultValue: "GET",
				Description:  "HTTP method",
				Options: []FieldOption{
					{Value: "GET", Label: "GET"},
					{Value: "POST", Label: "POST"},
					{Value: "PUT", Label: "PUT"},
					{Value: "PATCH", Label: "PATCH"},
					{Value: "DELETE", Label: "DELETE"},
				},
			},
			{
				Name:        "url",
				Label:       "URL",
				Type:        FieldTypeURL,
				Required:    true,
				Description: "Request URL (supports {{variables}})",
				Placeholder: "https://api.example.com/users/{{trigger.body.user_id}}",
			},
			{
				Name:        "headers",
				Label:       "Headers",
				Type:        FieldTypeKeyValue,
				Required:    false,
				Description: "HTTP headers",
				Placeholder: "Authorization: Bearer {{token}}",
			},
			{
				Name:        "body",
				Label:       "Request Body",
				Type:        FieldTypeJSON,
				Required:    false,
				Description: "Request body (JSON)",
				Placeholder: `{"user_id": "{{trigger.body.user_id}}"}`,
			},
			{
				Name:         "timeout",
				Label:        "Timeout (seconds)",
				Type:         FieldTypeNumber,
				Required:     false,
				DefaultValue: 30,
				Description:  "Request timeout",
			},
			{
				Name:         "retry_on_failure",
				Label:        "Retry on Failure",
				Type:         FieldTypeBoolean,
				Required:     false,
				DefaultValue: false,
				Description:  "Automatically retry failed requests",
			},
			{
				Name:         "max_retries",
				Label:        "Max Retries",
				Type:         FieldTypeNumber,
				Required:     false,
				DefaultValue: 3,
				Description:  "Maximum retry attempts",
				DependsOn: &Dependency{
					Field: "retry_on_failure",
					Value: true,
				},
			},
		},
	}
}

// ============================================================================
// 3. SEND_MESSAGE Schema
// ============================================================================

func GetSendMessageSchema() NodeConfigSchema {
	return NodeConfigSchema{
		NodeType:    "SEND_MESSAGE",
		DisplayName: "Send Message",
		Description: "Send messages via channels (WhatsApp, SMS, etc.)",
		Icon:        "üí¨",
		Category:    "Communication",
		Fields: []FieldSchema{
			{
				Name:        "channel_id",
				Label:       "Channel ID",
				Type:        FieldTypeString,
				Required:    true,
				Description: "Channel to send through (or use {{trigger.body.channel_id}})",
				Placeholder: "{{trigger.body.channel_id}}",
			},
			{
				Name:        "recipient_id",
				Label:       "Recipient",
				Type:        FieldTypeString,
				Required:    true,
				Description: "Phone number or user ID",
				Placeholder: "+51987654321 or {{trigger.body.sender_id}}",
			},
			{
				Name:        "text",
				Label:       "Message Text",
				Type:        FieldTypeTextarea,
				Required:    true,
				Description: "Message content (supports {{variables}})",
				Placeholder: "Hello {{trigger.body.user_name}}, your order is ready!",
			},
			{
				Name:         "message_type",
				Label:        "Message Type",
				Type:         FieldTypeSelect,
				Required:     false,
				DefaultValue: "text",
				Description:  "Type of message",
				Options: []FieldOption{
					{Value: "text", Label: "Text"},
					{Value: "image", Label: "Image"},
					{Value: "document", Label: "Document"},
					{Value: "audio", Label: "Audio"},
					{Value: "video", Label: "Video"},
				},
			},
			{
				Name:        "attachments",
				Label:       "Attachments",
				Type:        FieldTypeArray,
				Required:    false,
				Description: "Media attachments (URLs or file paths)",
				Placeholder: "[{\"type\": \"image\", \"url\": \"https://...\"}]",
			},
		},
	}
}

// ============================================================================
// 4. TRANSFORM Schema
// ============================================================================

func GetTransformSchema() NodeConfigSchema {
	return NodeConfigSchema{
		NodeType:    "TRANSFORM",
		DisplayName: "Transform Data",
		Description: "Map and transform data fields",
		Icon:        "üîÑ",
		Category:    "Data",
		Fields: []FieldSchema{
			{
				Name:        "mappings",
				Label:       "Field Mappings",
				Type:        FieldTypeKeyValue,
				Required:    true,
				Description: "Map source fields to target fields",
				Placeholder: "user_name: {{trigger.body.name}}\nuser_email: {{trigger.body.email}}",
			},
		},
	}
}

// ============================================================================
// 5. CONDITION Schema
// ============================================================================

func GetConditionSchema() NodeConfigSchema {
	return NodeConfigSchema{
		NodeType:    "CONDITION",
		DisplayName: "Condition",
		Description: "Branch workflow based on conditions",
		Icon:        "üîÄ",
		Category:    "Logic",
		Fields: []FieldSchema{
			{
				Name:        "condition_type",
				Label:       "Condition Type",
				Type:        FieldTypeSelect,
				Required:    true,
				Description: "Type of condition to check",
				Options: []FieldOption{
					{Value: "equals", Label: "Equals", Description: "Check if values are equal"},
					{Value: "contains", Label: "Contains", Description: "Check if text contains substring"},
					{Value: "exists", Label: "Exists", Description: "Check if field exists"},
					{Value: "regex", Label: "Regex", Description: "Match regular expression"},
				},
			},
			{
				Name:        "field",
				Label:       "Field to Check",
				Type:        FieldTypeString,
				Required:    true,
				Description: "Field path (e.g., trigger.body.status)",
				Placeholder: "trigger.body.status",
			},
			{
				Name:        "value",
				Label:       "Expected Value",
				Type:        FieldTypeString,
				Required:    false,
				Description: "Value to compare against",
				Placeholder: "active",
			},
			{
				Name:         "case_insensitive",
				Label:        "Case Insensitive",
				Type:         FieldTypeBoolean,
				Required:     false,
				DefaultValue: false,
				Description:  "Ignore case when comparing",
			},
		},
	}
}

// ============================================================================
// 6. SWITCH Schema
// ============================================================================

func GetSwitchSchema() NodeConfigSchema {
	return NodeConfigSchema{
		NodeType:    "SWITCH",
		DisplayName: "Switch",
		Description: "Route to different nodes based on value",
		Icon:        "üéõÔ∏è",
		Category:    "Logic",
		Fields: []FieldSchema{
			{
				Name:        "field",
				Label:       "Field to Evaluate",
				Type:        FieldTypeString,
				Required:    true,
				Description: "Field path to evaluate",
				Placeholder: "trigger.body.event_type",
			},
			{
				Name:        "cases",
				Label:       "Cases",
				Type:        FieldTypeKeyValue,
				Required:    true,
				Description: "Map values to node IDs (case_value: node_id)",
				Placeholder: "user.created: send_welcome\nuser.deleted: send_goodbye\ndefault: log_event",
			},
		},
	}
}

// ============================================================================
// 7. LOOP Schema
// ============================================================================

func GetLoopSchema() NodeConfigSchema {
	return NodeConfigSchema{
		NodeType:    "LOOP",
		DisplayName: "Loop",
		Description: "Iterate over arrays or collections",
		Icon:        "üîÅ",
		Category:    "Logic",
		Fields: []FieldSchema{
			{
				Name:        "iterate_over",
				Label:       "Collection",
				Type:        FieldTypeString,
				Required:    true,
				Description: "Array or collection to iterate",
				Placeholder: "trigger.body.items",
			},
			{
				Name:         "item_var",
				Label:        "Item Variable Name",
				Type:         FieldTypeString,
				Required:     false,
				DefaultValue: "item",
				Description:  "Variable name for current item",
			},
			{
				Name:         "index_var",
				Label:        "Index Variable Name",
				Type:         FieldTypeString,
				Required:     false,
				DefaultValue: "index",
				Description:  "Variable name for current index",
			},
			{
				Name:        "body_node",
				Label:       "Body Node ID",
				Type:        FieldTypeString,
				Required:    true,
				Description: "Node to execute for each item",
				Placeholder: "process_item",
			},
			{
				Name:         "max_iterations",
				Label:        "Max Iterations",
				Type:         FieldTypeNumber,
				Required:     false,
				DefaultValue: 1000,
				Description:  "Maximum number of iterations",
				Validation: &Validation{
					Min:     ptrx.Float32(1),
					Max:     ptrx.Float32(10000),
					Message: "Max iterations must be between 1 and 10000",
				},
			},
		},
	}
}

// ============================================================================
// 8. VALIDATE Schema
// ============================================================================

func GetValidateSchema() NodeConfigSchema {
	return NodeConfigSchema{
		NodeType:    "VALIDATE",
		DisplayName: "Validate Data",
		Description: "Validate input data against rules",
		Icon:        "‚úÖ",
		Category:    "Data",
		Fields: []FieldSchema{
			{
				Name:        "schema",
				Label:       "Validation Rules",
				Type:        FieldTypeKeyValue,
				Required:    true,
				Description: "Field validation rules (field: rule)",
				Placeholder: "email: required,email\nage: number,min:18\nname: required,string",
			},
			{
				Name:         "fail_on_error",
				Label:        "Fail on Validation Error",
				Type:         FieldTypeBoolean,
				Required:     false,
				DefaultValue: true,
				Description:  "Stop workflow if validation fails",
			},
		},
	}
}

// ============================================================================
// 9. DELAY Schema
// ============================================================================

func GetDelaySchema() NodeConfigSchema {
	return NodeConfigSchema{
		NodeType:    "DELAY",
		DisplayName: "Delay",
		Description: "Pause workflow execution",
		Icon:        "‚è±Ô∏è",
		Category:    "Control",
		Fields: []FieldSchema{
			{
				Name:        "duration",
				Label:       "Duration",
				Type:        FieldTypeString,
				Required:    false,
				Description: "Delay duration (e.g., 5s, 10m, 1h)",
				Placeholder: "5m",
			},
			{
				Name:        "duration_ms",
				Label:       "Duration (milliseconds)",
				Type:        FieldTypeNumber,
				Required:    false,
				Description: "Delay in milliseconds",
				Placeholder: "5000",
			},
			{
				Name:        "duration_seconds",
				Label:       "Duration (seconds)",
				Type:        FieldTypeNumber,
				Required:    false,
				Description: "Delay in seconds",
				Placeholder: "300",
			},
		},
	}
}

// ============================================================================
// 10. ACTION Schema
// ============================================================================

func GetActionSchema() NodeConfigSchema {
	return NodeConfigSchema{
		NodeType:    "ACTION",
		DisplayName: "Action",
		Description: "Execute custom actions",
		Icon:        "‚ö°",
		Category:    "Utility",
		Fields: []FieldSchema{
			{
				Name:        "action_type",
				Label:       "Action Type",
				Type:        FieldTypeSelect,
				Required:    true,
				Description: "Type of action to perform",
				Options: []FieldOption{
					{Value: "console_log", Label: "Console Log", Description: "Log to console"},
					{Value: "set_context", Label: "Set Context", Description: "Set workflow variables"},
				},
			},
			{
				Name:        "message",
				Label:       "Message",
				Type:        FieldTypeTextarea,
				Required:    false,
				Description: "Message to log (for console_log)",
				Placeholder: "Processing user: {{trigger.body.user_id}}",
				DependsOn: &Dependency{
					Field: "action_type",
					Value: "console_log",
				},
			},
			{
				Name:        "context",
				Label:       "Context Data",
				Type:        FieldTypeJSON,
				Required:    false,
				Description: "Variables to set (for set_context)",
				Placeholder: `{"user_id": "{{trigger.body.user_id}}"}`,
				DependsOn: &Dependency{
					Field: "action_type",
					Value: "set_context",
				},
			},
			{
				Name:         "print_input",
				Label:        "Print Input Data",
				Type:         FieldTypeBoolean,
				Required:     false,
				DefaultValue: false,
				Description:  "Also log input data",
				DependsOn: &Dependency{
					Field: "action_type",
					Value: "console_log",
				},
			},
		},
	}
}
package node

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/Abraxas-365/craftable/errx"
	"github.com/Abraxas-365/relay/engine"
)

type TransformExecutor struct {
	evaluator engine.ExpressionEvaluator
}

var _ engine.NodeExecutor = (*TransformExecutor)(nil)

func NewTransformExecutor(evaluator engine.ExpressionEvaluator) *TransformExecutor {
	return &TransformExecutor{evaluator: evaluator}
}

func (e *TransformExecutor) Execute(ctx context.Context, node engine.WorkflowNode, input map[string]any) (*engine.NodeResult, error) {
	startTime := time.Now()
	result := &engine.NodeResult{
		NodeID:    node.ID,
		NodeName:  node.Name,
		Timestamp: startTime,
		Output:    make(map[string]any),
	}

	// Extract transform config
	transformConfig, err := engine.ExtractTransformConfig(node.Config)
	if err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("invalid transform config: %v", err)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	log.Printf("üîÑ Transform: mapping %d fields", len(transformConfig.Mappings))

	// Transform each mapping
	transformed := make(map[string]any)
	errors := make([]string, 0)

	for targetKey, sourceExpr := range transformConfig.Mappings {
		log.Printf("   üìç Mapping '%s' from: %v", targetKey, sourceExpr)

		// Evaluate expression
		value, err := e.evaluator.Evaluate(ctx, sourceExpr, input)
		if err != nil {
			errMsg := fmt.Sprintf("failed to evaluate '%s': %v", targetKey, err)
			log.Printf("   ‚ö†Ô∏è  %s", errMsg)
			errors = append(errors, errMsg)
			continue
		}

		transformed[targetKey] = value
		log.Printf("   ‚úÖ '%s' = %v", targetKey, value)
	}

	// If all mappings failed, mark as failed
	if len(errors) > 0 && len(transformed) == 0 {
		result.Success = false
		result.Error = fmt.Sprintf("all transformations failed: %v", errors)
		result.Output["errors"] = errors
		result.Duration = time.Since(startTime).Milliseconds()
		return result, errx.New(result.Error, errx.TypeInternal)
	}

	result.Success = true
	result.Output = transformed

	if len(errors) > 0 {
		result.Output["errors"] = errors
		result.Output["partial_success"] = true
	}

	result.Duration = time.Since(startTime).Milliseconds()
	log.Printf("‚úÖ Transform completed: %d fields mapped, %d errors", len(transformed), len(errors))

	return result, nil
}

func (e *TransformExecutor) SupportsType(nodeType engine.NodeType) bool {
	return nodeType == engine.NodeTypeTransform
}

func (e *TransformExecutor) ValidateConfig(config map[string]any) error {
	transformConfig, err := engine.ExtractTransformConfig(config)
	if err != nil {
		return err
	}
	return transformConfig.Validate()
}
package node

import (
	"context"
	"fmt"
	"log"
	"maps"
	"time"

	"github.com/Abraxas-365/craftable/ai/llm"
	"github.com/Abraxas-365/craftable/ai/llm/agentx"
	"github.com/Abraxas-365/relay/engine"
	"github.com/Abraxas-365/relay/pkg/agent"
	"github.com/Abraxas-365/relay/pkg/kernel"
)

type AIAgentExecutor struct {
	agentChatRepo agent.AgentChatRepository
	evaluator     engine.ExpressionEvaluator
}

func NewAIAgentExecutor(
	agentChatRepo agent.AgentChatRepository,
	evaluator engine.ExpressionEvaluator,
) *AIAgentExecutor {
	return &AIAgentExecutor{
		agentChatRepo: agentChatRepo,
		evaluator:     evaluator,
	}
}

func (e *AIAgentExecutor) Execute(ctx context.Context, node engine.WorkflowNode, input map[string]any) (*engine.NodeResult, error) {
	startTime := time.Now()
	result := &engine.NodeResult{
		NodeID:    node.ID,
		NodeName:  node.Name,
		Timestamp: startTime,
		Output:    make(map[string]any),
	}

	// Extract AI config
	aiConfig, err := engine.ExtractAIAgentConfig(node.Config)
	if err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("invalid AI agent config: %v", err)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	// Create resolver
	resolver := NewFieldResolver(input, node.Config, e.evaluator)

	// Get user message (priority: config prompt -> webhook message -> default)
	userMessage := resolver.GetString("prompt", "")
	if userMessage == "" {
		userMessage = resolver.GetString("user_prompt", "")
	}
	if userMessage == "" {
		userMessage = resolver.GetString("message", "")
	}
	if userMessage == "" {
		userMessage = resolver.GetString("text", "")
	}
	if userMessage == "" {
		userMessage = "Generate a creative response."
	}

	// Get tenant ID
	tenantID, _ := resolver.GetTenantID()

	// Get conversation ID for memory
	conversationID := resolver.GetString("conversation_id", "")
	if conversationID == "" {
		conversationID = resolver.GetString("sender_id", "")
	}

	log.Printf("ü§ñ AI Agent '%s' - Model: %s, Memory: %v", node.Name, aiConfig.Model, aiConfig.UseMemory)

	var responseText string
	var metadata map[string]any

	// Execute with or without memory
	if aiConfig.UseMemory && conversationID != "" && tenantID != "" {
		responseText, metadata, err = e.executeWithAgent(ctx, aiConfig, userMessage, string(tenantID), conversationID, input)
	} else {
		responseText, metadata, err = e.executeWithLLM(ctx, aiConfig, userMessage, input)
	}

	if err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("AI execution failed: %v", err)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	result.Success = true
	result.Output["ai_response"] = responseText
	result.Output["response"] = responseText
	result.Output["model"] = aiConfig.Model
	result.Output["provider"] = aiConfig.Provider

	if metadata != nil {
		maps.Copy(result.Output, metadata)
	}

	result.Duration = time.Since(startTime).Milliseconds()
	log.Printf("‚úÖ AI Agent completed in %dms", result.Duration)

	return result, nil
}

func (e *AIAgentExecutor) executeWithLLM(
	ctx context.Context,
	config *engine.AIAgentConfig,
	userMessage string,
	input map[string]any,
) (string, map[string]any, error) {
	client := config.GetLLMClient()

	messages := []llm.Message{
		llm.NewSystemMessage(config.SystemPrompt),
		llm.NewUserMessage(userMessage),
	}

	response, err := client.Chat(ctx, messages, config.GetLLMOptions()...)
	if err != nil {
		return "", nil, err
	}

	metadata := map[string]any{
		"mode": "llm",
		"tokens_used": map[string]any{
			"prompt":     response.Usage.PromptTokens,
			"completion": response.Usage.CompletionTokens,
			"total":      response.Usage.TotalTokens,
		},
	}

	return response.Message.Content, metadata, nil
}

func (e *AIAgentExecutor) executeWithAgent(
	ctx context.Context,
	config *engine.AIAgentConfig,
	userMessage string,
	tenantID string,
	conversationID string,
	input map[string]any,
) (string, map[string]any, error) {
	llmClient := config.GetLLMClient()

	memory := agent.NewSessionMemory(
		ctx,
		kernel.TenantID(tenantID),
		kernel.SessionID(conversationID),
		config.SystemPrompt,
		[]llm.Message{},
		e.agentChatRepo,
	)

	agentOptions := []agentx.AgentOption{
		agentx.WithOptions(config.GetLLMOptions()...),
		agentx.WithMaxAutoIterations(config.GetMaxAutoIterations()),
		agentx.WithMaxTotalIterations(config.GetMaxTotalIterations()),
	}

	agentInstance := agentx.New(llmClient, memory, agentOptions...)

	response, err := agentInstance.Run(ctx, userMessage)
	if err != nil {
		return "", nil, err
	}

	metadata := map[string]any{
		"mode":            "agent",
		"conversation_id": conversationID,
		"has_memory":      true,
	}

	return response, metadata, nil
}

func (e *AIAgentExecutor) SupportsType(nodeType engine.NodeType) bool {
	return nodeType == engine.NodeTypeAIAgent
}

func (e *AIAgentExecutor) ValidateConfig(config map[string]any) error {
	aiConfig, err := engine.ExtractAIAgentConfig(config)
	if err != nil {
		return err
	}
	return aiConfig.Validate()
}
package node

import (
	"context"
	"fmt"
	"log"
	"regexp"
	"strings"
	"time"

	"github.com/Abraxas-365/relay/engine"
)

type ValidateExecutor struct{}

var _ engine.NodeExecutor = (*ValidateExecutor)(nil)

func NewValidateExecutor() *ValidateExecutor {
	return &ValidateExecutor{}
}

func (e *ValidateExecutor) Execute(ctx context.Context, node engine.WorkflowNode, input map[string]any) (*engine.NodeResult, error) {
	startTime := time.Now()
	result := &engine.NodeResult{
		NodeID:    node.ID,
		NodeName:  node.Name,
		Timestamp: startTime,
		Output:    make(map[string]any),
	}

	// Extract validate config
	validateConfig, err := engine.ExtractValidateConfig(node.Config)
	if err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("invalid validate config: %v", err)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	log.Printf("‚úÖ Validate: checking %d fields", len(validateConfig.Schema))

	validationErrors := make([]string, 0)
	validFields := make(map[string]bool)

	// Validate each field
	for field, rule := range validateConfig.Schema {
		ruleStr, _ := rule.(string)
		value := getNestedFieldValue(input, field)

		log.Printf("   üîç Validating '%s' with rule '%s'", field, ruleStr)

		if err := e.validateField(field, value, ruleStr); err != nil {
			validationErrors = append(validationErrors, err.Error())
			validFields[field] = false
			log.Printf("   ‚ùå %s", err.Error())
		} else {
			validFields[field] = true
			log.Printf("   ‚úÖ '%s' is valid", field)
		}
	}

	isValid := len(validationErrors) == 0

	// Set result based on fail_on_error setting
	result.Success = !validateConfig.ShouldFailOnError() || isValid
	result.Output["valid"] = isValid
	result.Output["errors"] = validationErrors
	result.Output["fields"] = validFields
	result.Output["error_count"] = len(validationErrors)

	if !isValid && validateConfig.ShouldFailOnError() {
		result.Error = fmt.Sprintf("validation failed: %v", validationErrors)
	}

	result.Duration = time.Since(startTime).Milliseconds()
	log.Printf("‚úÖ Validation completed: %d/%d fields valid", len(validFields)-len(validationErrors), len(validFields))

	return result, nil
}

func (e *ValidateExecutor) validateField(field string, value any, rule string) error {
	// Parse rule (can be comma-separated: "required,email")
	rules := strings.Split(rule, ",")

	for _, r := range rules {
		r = strings.TrimSpace(r)

		switch r {
		case "required":
			if value == nil || value == "" {
				return fmt.Errorf("field '%s' is required", field)
			}

		case "email":
			str, ok := value.(string)
			if !ok {
				return fmt.Errorf("field '%s' must be a string for email validation", field)
			}
			emailRegex := regexp.MustCompile(`^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$`)
			if !emailRegex.MatchString(str) {
				return fmt.Errorf("field '%s' must be a valid email", field)
			}

		case "number":
			if !isNumeric(value) {
				return fmt.Errorf("field '%s' must be a number", field)
			}

		case "string":
			if _, ok := value.(string); !ok {
				return fmt.Errorf("field '%s' must be a string", field)
			}

		case "url":
			str, ok := value.(string)
			if !ok {
				return fmt.Errorf("field '%s' must be a string for URL validation", field)
			}
			if !strings.HasPrefix(str, "http://") && !strings.HasPrefix(str, "https://") {
				return fmt.Errorf("field '%s' must be a valid URL", field)
			}

		default:
			// Check for min/max rules
			if strings.HasPrefix(r, "min:") {
				// TODO: Implement min validation
			} else if strings.HasPrefix(r, "max:") {
				// TODO: Implement max validation
			} else {
				log.Printf("   ‚ö†Ô∏è  Unknown validation rule: %s", r)
			}
		}
	}

	return nil
}

func isNumeric(v any) bool {
	switch v.(type) {
	case int, int8, int16, int32, int64:
		return true
	case uint, uint8, uint16, uint32, uint64:
		return true
	case float32, float64:
		return true
	default:
		return false
	}
}

func (e *ValidateExecutor) SupportsType(nodeType engine.NodeType) bool {
	return nodeType == engine.NodeTypeValidate
}

func (e *ValidateExecutor) ValidateConfig(config map[string]any) error {
	validateConfig, err := engine.ExtractValidateConfig(config)
	if err != nil {
		return err
	}
	return validateConfig.Validate()
}
package node

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/Abraxas-365/relay/channels"
	"github.com/Abraxas-365/relay/engine"
	"github.com/Abraxas-365/relay/pkg/kernel"
)

type SendMessageExecutor struct {
	channelManager channels.ChannelManager
	evaluator      engine.ExpressionEvaluator
}

func NewSendMessageExecutor(
	channelManager channels.ChannelManager,
	evaluator engine.ExpressionEvaluator,
) *SendMessageExecutor {
	return &SendMessageExecutor{
		channelManager: channelManager,
		evaluator:      evaluator,
	}
}

func (e *SendMessageExecutor) Execute(ctx context.Context, node engine.WorkflowNode, input map[string]any) (*engine.NodeResult, error) {
	startTime := time.Now()
	result := &engine.NodeResult{
		NodeID:    node.ID,
		NodeName:  node.Name,
		Timestamp: startTime,
		Output:    make(map[string]any),
	}

	// Create resolver
	resolver := NewFieldResolver(input, node.Config, e.evaluator)

	// Get tenant ID
	tenantID, err := resolver.GetTenantID()
	if err != nil {
		result.Success = false
		result.Error = "tenant_id not found"
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	// Resolve fields (priority: config -> webhook -> error)
	channelIDStr := resolver.GetString("channel_id", "")
	if channelIDStr == "" {
		result.Success = false
		result.Error = "channel_id is required"
		result.Duration = time.Since(startTime).Milliseconds()
		return result, fmt.Errorf("channel_id required")
	}

	recipientID := resolver.GetString("recipient_id", "")
	if recipientID == "" {
		// Try sender_id as fallback
		recipientID = resolver.GetString("sender_id", "")
	}
	if recipientID == "" {
		result.Success = false
		result.Error = "recipient_id is required"
		result.Duration = time.Since(startTime).Milliseconds()
		return result, fmt.Errorf("recipient_id required")
	}

	text := resolver.GetString("text", "")
	if text == "" {
		text = resolver.GetString("message", "") // Try 'message' as fallback
	}
	if text == "" {
		result.Success = false
		result.Error = "text is required"
		result.Duration = time.Since(startTime).Milliseconds()
		return result, fmt.Errorf("text required")
	}

	messageType := resolver.GetString("message_type", "text")

	log.Printf("üí¨ Sending message to %s via channel %s", recipientID, channelIDStr)
	log.Printf("   üìù Text: %s", truncateString(text, 50))

	// Build message
	messageContent := channels.MessageContent{
		Type: messageType,
		Text: text,
	}

	// Handle attachments
	if attachments := resolver.GetArray("attachments"); len(attachments) > 0 {
		parsedAttachments := make([]channels.Attachment, 0, len(attachments))
		for _, att := range attachments {
			if attStr, ok := att.(string); ok {
				parsedAttachments = append(parsedAttachments, channels.Attachment{
					Type: "document",
					URL:  attStr,
				})
			} else if attMap, ok := att.(map[string]any); ok {
				attachment := channels.Attachment{
					Type:     getStringFromMap(attMap, "type", "document"),
					URL:      getStringFromMap(attMap, "url", ""),
					MimeType: getStringFromMap(attMap, "mime_type", ""),
					Filename: getStringFromMap(attMap, "filename", ""),
					Caption:  getStringFromMap(attMap, "caption", ""),
				}
				parsedAttachments = append(parsedAttachments, attachment)
			}
		}
		messageContent.Attachments = parsedAttachments
	}

	// Send message
	outgoingMsg := channels.OutgoingMessage{
		RecipientID: recipientID,
		Content:     messageContent,
		Metadata: map[string]any{
			"workflow_node_id":   node.ID,
			"workflow_node_name": node.Name,
			"timestamp":          time.Now().Unix(),
		},
	}

	if err := e.channelManager.SendMessage(ctx, tenantID, kernel.ChannelID(channelIDStr), outgoingMsg); err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("failed to send message: %v", err)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	result.Success = true
	result.Output["sent"] = true
	result.Output["channel_id"] = channelIDStr
	result.Output["recipient_id"] = recipientID
	result.Output["message_text"] = text
	result.Duration = time.Since(startTime).Milliseconds()

	log.Printf("‚úÖ Message sent successfully")
	return result, nil
}

func (e *SendMessageExecutor) SupportsType(nodeType engine.NodeType) bool {
	return nodeType == engine.NodeTypeSendMessage
}

func (e *SendMessageExecutor) ValidateConfig(config map[string]any) error {
	// Basic validation - text is required in config or will be from webhook
	return nil
}

func getStringFromMap(m map[string]any, key, defaultValue string) string {
	if val, ok := m[key].(string); ok {
		return val
	}
	return defaultValue
}

func truncateString(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen] + "..."
}
package node

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/Abraxas-365/craftable/errx"
	"github.com/Abraxas-365/relay/engine"
)

type LoopExecutor struct{}

var _ engine.NodeExecutor = (*LoopExecutor)(nil)

func NewLoopExecutor() *LoopExecutor {
	return &LoopExecutor{}
}

func (e *LoopExecutor) Execute(ctx context.Context, node engine.WorkflowNode, input map[string]any) (*engine.NodeResult, error) {
	startTime := time.Now()
	result := &engine.NodeResult{
		NodeID:    node.ID,
		NodeName:  node.Name,
		Timestamp: startTime,
		Output:    make(map[string]any),
	}

	// Extract loop config
	loopConfig, err := engine.ExtractLoopConfig(node.Config)
	if err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("invalid loop config: %v", err)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	log.Printf("üîÅ Loop: iterating over '%s'", loopConfig.IterateOver)

	// Get collection to iterate
	collectionValue := getNestedFieldValue(input, loopConfig.IterateOver)
	if collectionValue == nil {
		result.Success = false
		result.Error = fmt.Sprintf("field '%s' not found", loopConfig.IterateOver)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, errx.New(result.Error, errx.TypeValidation)
	}

	// Convert to slice
	var items []any
	switch v := collectionValue.(type) {
	case []any:
		items = v
	case []string:
		items = make([]any, len(v))
		for i, s := range v {
			items[i] = s
		}
	case []int:
		items = make([]any, len(v))
		for i, n := range v {
			items[i] = n
		}
	default:
		result.Success = false
		result.Error = fmt.Sprintf("iterate_over must be an array, got %T", collectionValue)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, errx.New(result.Error, errx.TypeValidation)
	}

	log.Printf("   üìä Found %d items to iterate", len(items))

	// Execute loop
	results := make([]map[string]any, 0, len(items))
	maxIterations := loopConfig.GetMaxIterations()

	for i, item := range items {
		if i >= maxIterations {
			log.Printf("   ‚ö†Ô∏è  Max iterations reached: %d", maxIterations)
			break
		}

		log.Printf("   üîÑ Iteration %d/%d", i+1, len(items))

		// Create iteration result
		iterResult := map[string]any{
			"index": i,
			"item":  item,
		}

		// TODO: In a real implementation, you would execute the body_node here
		// For now, we just collect the items
		// This would require recursive workflow execution

		results = append(results, iterResult)
	}

	result.Success = true
	result.Output["results"] = results
	result.Output["count"] = len(results)
	result.Output["total_items"] = len(items)

	// Set next node to body_node for first iteration
	// (This is a simplified implementation - real loops need more complex state management)
	if len(items) > 0 {
		result.Output["body_node"] = loopConfig.BodyNode
	}

	result.Duration = time.Since(startTime).Milliseconds()
	log.Printf("‚úÖ Loop completed: %d iterations", len(results))

	return result, nil
}

func (e *LoopExecutor) SupportsType(nodeType engine.NodeType) bool {
	return nodeType == engine.NodeTypeLoop
}

func (e *LoopExecutor) ValidateConfig(config map[string]any) error {
	loopConfig, err := engine.ExtractLoopConfig(config)
	if err != nil {
		return err
	}
	return loopConfig.Validate()
}
package node

import (
	"context"
	"fmt"
	"strings"
	"time"

	"github.com/Abraxas-365/craftable/errx"
	"github.com/Abraxas-365/relay/engine"
)

// ConditionExecutor ejecuta condiciones
type ConditionExecutor struct{}

var _ engine.NodeExecutor = (*ConditionExecutor)(nil)

func NewConditionExecutor() *ConditionExecutor {
	return &ConditionExecutor{}
}

func (ce *ConditionExecutor) Execute(ctx context.Context, node engine.WorkflowNode, input map[string]any) (*engine.NodeResult, error) {
	startTime := time.Now()

	result := &engine.NodeResult{
		NodeID:    node.ID,
		NodeName:  node.Name,
		Timestamp: startTime,
		Output:    make(map[string]any),
	}

	// Obtener configuraci√≥n
	conditionType, ok := node.Config["condition_type"].(string)
	if !ok {
		result.Success = false
		result.Error = "missing condition_type"
		result.Duration = time.Since(startTime).Milliseconds()
		return result, errx.New("missing condition_type", errx.TypeValidation)
	}

	var conditionMet bool
	var err error

	switch conditionType {
	case "contains":
		conditionMet, err = ce.evaluateContains(node.Config, input)
	case "equals":
		conditionMet, err = ce.evaluateEquals(node.Config, input)
	case "exists":
		conditionMet, err = ce.evaluateExists(node.Config, input)
	case "regex":
		conditionMet, err = ce.evaluateRegex(node.Config, input)
	default:
		result.Success = false
		result.Error = fmt.Sprintf("unknown condition type: %s", conditionType)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, errx.New("unknown condition type", errx.TypeValidation)
	}

	if err != nil {
		result.Success = false
		result.Error = err.Error()
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	result.Success = true
	result.Output["condition_met"] = conditionMet
	result.Duration = time.Since(startTime).Milliseconds()

	return result, nil
}

func (ce *ConditionExecutor) evaluateContains(config map[string]any, input map[string]any) (bool, error) {
	field, ok := config["field"].(string)
	if !ok {
		return false, errx.New("missing field", errx.TypeValidation)
	}

	value, ok := config["value"].(string)
	if !ok {
		return false, errx.New("missing value", errx.TypeValidation)
	}

	fieldValue, ok := input[field].(string)
	if !ok {
		return false, nil
	}

	caseInsensitive := config["case_insensitive"] == true
	if caseInsensitive {
		return strings.Contains(strings.ToLower(fieldValue), strings.ToLower(value)), nil
	}

	return strings.Contains(fieldValue, value), nil
}

func (ce *ConditionExecutor) evaluateEquals(config map[string]any, input map[string]any) (bool, error) {
	field, ok := config["field"].(string)
	if !ok {
		return false, errx.New("missing field", errx.TypeValidation)
	}

	expectedValue := config["value"]
	actualValue, exists := input[field]

	if !exists {
		return false, nil
	}

	return fmt.Sprint(actualValue) == fmt.Sprint(expectedValue), nil
}

func (ce *ConditionExecutor) evaluateExists(config map[string]any, input map[string]any) (bool, error) {
	field, ok := config["field"].(string)
	if !ok {
		return false, errx.New("missing field", errx.TypeValidation)
	}

	_, exists := input[field]
	return exists, nil
}

func (ce *ConditionExecutor) evaluateRegex(config map[string]any, input map[string]any) (bool, error) {
	// TODO: Implementar evaluaci√≥n de regex
	return false, errx.New("regex evaluation not implemented", errx.TypeInternal)
}

func (ce *ConditionExecutor) SupportsType(nodeType engine.NodeType) bool {
	return nodeType == engine.NodeTypeCondition
}

func (ce *ConditionExecutor) ValidateConfig(config map[string]any) error {
	conditionType, ok := config["condition_type"].(string)
	if !ok {
		return errx.New("condition_type is required", errx.TypeValidation)
	}

	switch conditionType {
	case "contains", "equals", "exists":
		if _, ok := config["field"].(string); !ok {
			return errx.New("field is required", errx.TypeValidation)
		}
	case "regex":
		if _, ok := config["pattern"].(string); !ok {
			return errx.New("pattern is required for regex", errx.TypeValidation)
		}
	default:
		return errx.New("unknown condition type", errx.TypeValidation)
	}

	return nil
}
package node

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"time"

	"github.com/Abraxas-365/relay/engine"
	"slices"
)

type HTTPExecutor struct {
	httpClient *http.Client
	evaluator  engine.ExpressionEvaluator
}

func NewHTTPExecutor(evaluator engine.ExpressionEvaluator) *HTTPExecutor {
	return &HTTPExecutor{
		httpClient: &http.Client{Timeout: 60 * time.Second},
		evaluator:  evaluator,
	}
}

func (e *HTTPExecutor) Execute(ctx context.Context, node engine.WorkflowNode, input map[string]any) (*engine.NodeResult, error) {
	startTime := time.Now()
	result := &engine.NodeResult{
		NodeID:    node.ID,
		NodeName:  node.Name,
		Timestamp: startTime,
		Output:    make(map[string]any),
	}

	// Extract HTTP config
	httpConfig, err := engine.ExtractHTTPConfig(node.Config)
	if err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("invalid HTTP config: %v", err)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	// Create resolver for template rendering
	resolver := NewFieldResolver(input, node.Config, e.evaluator)

	// Render URL with templates
	url := resolver.RenderTemplate(httpConfig.URL)

	// Render headers
	headers := make(map[string]string)
	for k, v := range httpConfig.Headers {
		headers[k] = resolver.RenderTemplate(v)
	}

	// Render body
	body := resolver.RenderMap(httpConfig.Body)

	log.Printf("üåê HTTP Request: %s %s", httpConfig.GetMethod(), url)

	// Build request
	var bodyReader io.Reader
	if len(body) > 0 {
		bodyJSON, err := json.Marshal(body)
		if err != nil {
			result.Success = false
			result.Error = fmt.Sprintf("failed to marshal body: %v", err)
			result.Duration = time.Since(startTime).Milliseconds()
			return result, err
		}
		bodyReader = bytes.NewBuffer(bodyJSON)
	}

	req, err := http.NewRequestWithContext(ctx, httpConfig.GetMethod(), url, bodyReader)
	if err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("failed to create request: %v", err)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	// Add headers
	for key, value := range headers {
		req.Header.Set(key, value)
	}
	if bodyReader != nil && req.Header.Get("Content-Type") == "" {
		req.Header.Set("Content-Type", "application/json")
	}

	// Execute request
	resp, err := e.httpClient.Do(req)
	if err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("request failed: %v", err)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}
	defer resp.Body.Close()

	// Read response
	bodyBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("failed to read response: %v", err)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	// Check success
	successCodes := httpConfig.GetSuccessCodes()
	isSuccess := slices.Contains(successCodes, resp.StatusCode)

	result.Success = isSuccess
	result.Output["status_code"] = resp.StatusCode
	result.Output["body"] = string(bodyBytes)

	// Try parse JSON
	var jsonBody any
	if err := json.Unmarshal(bodyBytes, &jsonBody); err == nil {
		result.Output["json"] = jsonBody
	}

	if !isSuccess {
		result.Error = fmt.Sprintf("HTTP %d: %s", resp.StatusCode, string(bodyBytes))
	}

	result.Duration = time.Since(startTime).Milliseconds()
	log.Printf("‚úÖ HTTP Response: %d", resp.StatusCode)

	return result, nil
}

func (e *HTTPExecutor) SupportsType(nodeType engine.NodeType) bool {
	return nodeType == engine.NodeTypeHTTP
}

func (e *HTTPExecutor) ValidateConfig(config map[string]any) error {
	httpConfig, err := engine.ExtractHTTPConfig(config)
	if err != nil {
		return err
	}
	return httpConfig.Validate()
}
package node

import (
	"context"
	"fmt"
	"regexp"
	"strings"

	"maps"

	"github.com/Abraxas-365/relay/engine"
	"github.com/Abraxas-365/relay/pkg/kernel"
)

// FieldResolver resolves field values from different sources with priority:
// 1. Webhook data (trigger.body)
// 2. Node config
// 3. Previous node output
// 4. Default value
type FieldResolver struct {
	data      map[string]any
	config    map[string]any
	evaluator engine.ExpressionEvaluator
}

func NewFieldResolver(data map[string]any, config map[string]any, evaluator engine.ExpressionEvaluator) *FieldResolver {
	return &FieldResolver{
		data:      data,
		config:    config,
		evaluator: evaluator,
	}
}

// ============================================================================
// Field Resolution (Priority: webhook -> config -> previous -> default)
// ============================================================================

// GetString resolves a string field with fallback order
func (r *FieldResolver) GetString(fieldName string, defaultValue string) string {
	// 1. Try webhook data (trigger.body.fieldName)
	if val := r.getFromWebhook(fieldName); val != "" {
		return r.RenderTemplate(val)
	}

	// 2. Try config
	if val, ok := r.config[fieldName].(string); ok && val != "" {
		return r.RenderTemplate(val)
	}

	// 3. Try previous node output
	if val, ok := r.data[fieldName].(string); ok && val != "" {
		return r.RenderTemplate(val)
	}

	// 4. Use default
	return defaultValue
}

// GetInt resolves an integer field
func (r *FieldResolver) GetInt(fieldName string, defaultValue int) int {
	// 1. Try webhook
	if val := r.getFromWebhook(fieldName); val != "" {
		if num := toInt(val); num != 0 {
			return num
		}
	}

	// 2. Try config
	if val, ok := r.config[fieldName]; ok {
		if num := toInt(val); num != 0 {
			return num
		}
	}

	// 3. Try data
	if val, ok := r.data[fieldName]; ok {
		if num := toInt(val); num != 0 {
			return num
		}
	}

	// 4. Default
	return defaultValue
}

// GetFloat resolves a float field
func (r *FieldResolver) GetFloat(fieldName string, defaultValue float64) float64 {
	// 1. Try webhook
	if val := r.getFromWebhook(fieldName); val != "" {
		if num := toFloat64(val); num != 0 {
			return num
		}
	}

	// 2. Try config
	if val, ok := r.config[fieldName]; ok {
		if num := toFloat64(val); num != 0 {
			return num
		}
	}

	// 3. Try data
	if val, ok := r.data[fieldName]; ok {
		if num := toFloat64(val); num != 0 {
			return num
		}
	}

	// 4. Default
	return defaultValue
}

// GetBool resolves a boolean field
func (r *FieldResolver) GetBool(fieldName string, defaultValue bool) bool {
	// 1. Try webhook
	if val := r.getFromWebhook(fieldName); val != "" {
		if b := toBool(val); b {
			return true
		}
	}

	// 2. Try config
	if val, ok := r.config[fieldName].(bool); ok {
		return val
	}

	// 3. Try data
	if val, ok := r.data[fieldName].(bool); ok {
		return val
	}

	// 4. Default
	return defaultValue
}

// GetMap resolves a map field
func (r *FieldResolver) GetMap(fieldName string) map[string]any {
	// 1. Try webhook
	if val := r.getFromWebhookNested(fieldName); val != nil {
		if m, ok := val.(map[string]any); ok {
			return m
		}
	}

	// 2. Try config
	if val, ok := r.config[fieldName].(map[string]any); ok {
		return val
	}

	// 3. Try data
	if val, ok := r.data[fieldName].(map[string]any); ok {
		return val
	}

	// 4. Empty map
	return make(map[string]any)
}

// GetArray resolves an array field
func (r *FieldResolver) GetArray(fieldName string) []any {
	// 1. Try webhook
	if val := r.getFromWebhookNested(fieldName); val != nil {
		if arr, ok := val.([]any); ok {
			return arr
		}
	}

	// 2. Try config
	if val, ok := r.config[fieldName].([]any); ok {
		return val
	}

	// 3. Try data
	if val, ok := r.data[fieldName].([]any); ok {
		return val
	}

	// 4. Empty array
	return []any{}
}

// ============================================================================
// Source Extractors
// ============================================================================

// getFromWebhook gets string value from trigger.body using field name
func (r *FieldResolver) getFromWebhook(fieldName string) string {
	// Check trigger.body.fieldName
	if trigger, ok := r.data["trigger"].(map[string]any); ok {
		if body, ok := trigger["body"].(map[string]any); ok {
			if val, ok := body[fieldName]; ok {
				return toString(val)
			}
		}
	}

	// Also check trigger.query.fieldName
	if trigger, ok := r.data["trigger"].(map[string]any); ok {
		if query, ok := trigger["query"].(map[string]any); ok {
			if val, ok := query[fieldName]; ok {
				return toString(val)
			}
		}
	}

	return ""
}

// getFromWebhookNested gets any value (including nested objects/arrays)
func (r *FieldResolver) getFromWebhookNested(fieldName string) any {
	// Check trigger.body.fieldName
	if trigger, ok := r.data["trigger"].(map[string]any); ok {
		if body, ok := trigger["body"].(map[string]any); ok {
			if val, ok := body[fieldName]; ok {
				return val
			}
		}
	}

	return nil
}

// GetNestedValue gets nested value using path like "trigger.body.user.name"
func (r *FieldResolver) GetNestedValue(path string) any {
	parts := strings.Split(path, ".")
	current := any(r.data)

	for _, part := range parts {
		switch v := current.(type) {
		case map[string]any:
			if val, ok := v[part]; ok {
				current = val
			} else {
				return nil
			}
		default:
			return nil
		}
	}

	return current
}

// ============================================================================
// Special Extractors
// ============================================================================

// GetTenantID extracts tenant ID from data
func (r *FieldResolver) GetTenantID() (kernel.TenantID, error) {
	// Try trigger.tenant_id
	if trigger, ok := r.data["trigger"].(map[string]any); ok {
		if tenantID, ok := trigger["tenant_id"].(string); ok && tenantID != "" {
			return kernel.TenantID(tenantID), nil
		}
	}

	// Try data.tenant_id
	if tenantID, ok := r.data["tenant_id"].(string); ok && tenantID != "" {
		return kernel.TenantID(tenantID), nil
	}

	// Try config.tenant_id
	if tenantID, ok := r.config["tenant_id"].(string); ok && tenantID != "" {
		return kernel.TenantID(tenantID), nil
	}

	return "", fmt.Errorf("tenant_id not found")
}

// GetChannelID extracts channel ID from data
func (r *FieldResolver) GetChannelID() (kernel.ChannelID, error) {
	channelIDStr := r.GetString("channel_id", "")
	if channelIDStr == "" {
		return "", fmt.Errorf("channel_id not found")
	}
	return kernel.ChannelID(channelIDStr), nil
}

// GetWorkflowID extracts workflow ID from data
func (r *FieldResolver) GetWorkflowID() (kernel.WorkflowID, error) {
	workflowIDStr := r.GetString("workflow_id", "")
	if workflowIDStr == "" {
		return "", fmt.Errorf("workflow_id not found")
	}
	return kernel.NewWorkflowID(workflowIDStr), nil
}

// ============================================================================
// Template Rendering
// ============================================================================

// RenderTemplate renders template strings like {{trigger.body.name}}
func (r *FieldResolver) RenderTemplate(template string) string {
	re := regexp.MustCompile(`\{\{(.+?)\}\}`)

	result := re.ReplaceAllStringFunc(template, func(match string) string {
		path := strings.TrimSpace(match[2 : len(match)-2])

		// Resolve the path
		value := r.GetNestedValue(path)
		if value != nil {
			return fmt.Sprintf("%v", value)
		}

		// Keep original if not found
		return match
	})

	return result
}

// RenderMap renders all string values in a map
func (r *FieldResolver) RenderMap(m map[string]any) map[string]any {
	result := make(map[string]any)
	for k, v := range m {
		if str, ok := v.(string); ok {
			result[k] = r.RenderTemplate(str)
		} else {
			result[k] = v
		}
	}
	return result
}

// RenderArray renders all string values in an array
func (r *FieldResolver) RenderArray(arr []any) []any {
	result := make([]any, len(arr))
	for i, v := range arr {
		if str, ok := v.(string); ok {
			result[i] = r.RenderTemplate(str)
		} else {
			result[i] = v
		}
	}
	return result
}

// ============================================================================
// Expression Evaluation (CEL support)
// ============================================================================

// Evaluate evaluates an expression using the CEL evaluator
func (r *FieldResolver) Evaluate(ctx context.Context, expression string) (any, error) {
	if r.evaluator == nil {
		return nil, fmt.Errorf("expression evaluator not available")
	}

	return r.evaluator.Evaluate(ctx, expression, r.data)
}

// ============================================================================
// Type Conversion Helpers
// ============================================================================

func toString(v any) string {
	if v == nil {
		return ""
	}
	if s, ok := v.(string); ok {
		return s
	}
	return fmt.Sprintf("%v", v)
}

func toInt(v any) int {
	switch val := v.(type) {
	case int:
		return val
	case int64:
		return int(val)
	case int32:
		return int(val)
	case float64:
		return int(val)
	case float32:
		return int(val)
	case string:
		var i int
		fmt.Sscanf(val, "%d", &i)
		return i
	default:
		return 0
	}
}

func toFloat64(v any) float64 {
	switch val := v.(type) {
	case float64:
		return val
	case float32:
		return float64(val)
	case int:
		return float64(val)
	case int64:
		return float64(val)
	case int32:
		return float64(val)
	case string:
		var f float64
		fmt.Sscanf(val, "%f", &f)
		return f
	default:
		return 0
	}
}

func toBool(v any) bool {
	switch val := v.(type) {
	case bool:
		return val
	case string:
		lower := strings.ToLower(val)
		return lower == "true" || lower == "yes" || lower == "1"
	case int:
		return val != 0
	case float64:
		return val != 0
	default:
		return false
	}
}

// ============================================================================
// Validation & Checks
// ============================================================================

// HasField checks if a field exists in any source
func (r *FieldResolver) HasField(fieldName string) bool {
	// Check webhook
	if r.getFromWebhook(fieldName) != "" {
		return true
	}

	// Check config
	if _, ok := r.config[fieldName]; ok {
		return true
	}

	// Check data
	if _, ok := r.data[fieldName]; ok {
		return true
	}

	return false
}

// IsEmpty checks if a value is empty
func (r *FieldResolver) IsEmpty(v any) bool {
	if v == nil {
		return true
	}

	switch val := v.(type) {
	case string:
		return val == ""
	case []any:
		return len(val) == 0
	case map[string]any:
		return len(val) == 0
	default:
		return false
	}
}

// RequireField ensures a field exists or returns error
func (r *FieldResolver) RequireField(fieldName string) error {
	if !r.HasField(fieldName) {
		return fmt.Errorf("required field '%s' not found", fieldName)
	}
	return nil
}

// ============================================================================
// Debugging Helpers
// ============================================================================

// GetAllKeys returns all available keys from all sources
func (r *FieldResolver) GetAllKeys() []string {
	keys := make(map[string]bool)

	// From webhook
	if trigger, ok := r.data["trigger"].(map[string]any); ok {
		if body, ok := trigger["body"].(map[string]any); ok {
			for k := range body {
				keys[k] = true
			}
		}
	}

	// From config
	for k := range r.config {
		keys[k] = true
	}

	// From data
	for k := range r.data {
		keys[k] = true
	}

	// Convert to slice
	result := make([]string, 0, len(keys))
	for k := range keys {
		result = append(result, k)
	}
	return result
}

// Dump returns all data for debugging
func (r *FieldResolver) Dump() map[string]any {
	return map[string]any{
		"data":   r.data,
		"config": r.config,
		"keys":   r.GetAllKeys(),
	}
}

// ============================================================================
// Field Mappings Support
// ============================================================================

// GetWithMapping gets a field with custom mapping support
func (r *FieldResolver) GetWithMapping(fieldName string, defaultValue string) string {
	// Check if there's a field_mappings configuration
	if mappings, ok := r.config["field_mappings"].(map[string]any); ok {
		// Check if this field has a custom mapping
		if mappedField, ok := mappings[fieldName].(string); ok {
			// Use the mapped field name instead
			fieldName = mappedField
		}
	}

	// Now get the value normally
	return r.GetString(fieldName, defaultValue)
}

// ApplyMappings applies field mappings to the entire config
func (r *FieldResolver) ApplyMappings() map[string]any {
	result := make(map[string]any)

	// Copy config
	maps.Copy(result, r.config)

	// Apply mappings if they exist
	if mappings, ok := r.config["field_mappings"].(map[string]any); ok {
		for targetField, sourceField := range mappings {
			if sourceStr, ok := sourceField.(string); ok {
				// Get value from the source field
				value := r.GetString(sourceStr, "")
				if value != "" {
					result[targetField] = value
				}
			}
		}
	}

	return result
}
package node

import (
	"context"
	"fmt"
	"log"
	"strings"
	"time"

	"github.com/Abraxas-365/relay/engine"
)

type SwitchExecutor struct{}

var _ engine.NodeExecutor = (*SwitchExecutor)(nil)

func NewSwitchExecutor() *SwitchExecutor {
	return &SwitchExecutor{}
}

func (e *SwitchExecutor) Execute(ctx context.Context, node engine.WorkflowNode, input map[string]any) (*engine.NodeResult, error) {
	startTime := time.Now()
	result := &engine.NodeResult{
		NodeID:    node.ID,
		NodeName:  node.Name,
		Timestamp: startTime,
		Output:    make(map[string]any),
	}

	// Extract switch config
	switchConfig, err := engine.ExtractSwitchConfig(node.Config)
	if err != nil {
		result.Success = false
		result.Error = fmt.Sprintf("invalid switch config: %v", err)
		result.Duration = time.Since(startTime).Milliseconds()
		return result, err
	}

	log.Printf("üîÄ Switch: evaluating field '%s'", switchConfig.Field)

	// Get field value from input using nested path
	fieldValue := getNestedFieldValue(input, switchConfig.Field)
	fieldValueStr := fmt.Sprint(fieldValue)

	log.Printf("   üìä Field value: %v (type: %T)", fieldValue, fieldValue)

	// Find matching case
	var matchedNodeID string
	var matchedCase string

	for caseValue, nodeID := range switchConfig.Cases {
		if caseValue == "default" {
			continue // Handle default separately
		}

		if fieldValueStr == caseValue {
			matchedNodeID = nodeID.(string)
			matchedCase = caseValue
			log.Printf("   ‚úÖ Matched case: '%s' -> node '%s'", caseValue, matchedNodeID)
			break
		}
	}

	// Check for default case if no match
	if matchedNodeID == "" {
		if defaultNode, ok := switchConfig.Cases["default"]; ok {
			matchedNodeID = defaultNode.(string)
			matchedCase = "default"
			log.Printf("   üìå Using default case -> node '%s'", matchedNodeID)
		} else {
			log.Printf("   ‚ö†Ô∏è  No matching case found and no default")
		}
	}

	result.Success = true
	result.Output["matched_case"] = matchedCase
	result.Output["field_value"] = fieldValue
	result.Output["field"] = switchConfig.Field

	// Set next node if matched
	if matchedNodeID != "" {
		result.Output["next_node"] = matchedNodeID
		// Store in context for workflow executor
		input["__next_node"] = matchedNodeID
	}

	result.Duration = time.Since(startTime).Milliseconds()
	return result, nil
}

func (e *SwitchExecutor) SupportsType(nodeType engine.NodeType) bool {
	return nodeType == engine.NodeTypeSwitch
}

func (e *SwitchExecutor) ValidateConfig(config map[string]any) error {
	switchConfig, err := engine.ExtractSwitchConfig(config)
	if err != nil {
		return err
	}
	return switchConfig.Validate()
}

// Helper to get nested field value (e.g., "trigger.message.text")
func getNestedFieldValue(data map[string]any, path string) any {
	parts := strings.Split(path, ".")
	current := any(data)

	for _, part := range parts {
		switch v := current.(type) {
		case map[string]any:
			if val, ok := v[part]; ok {
				current = val
			} else {
				return nil
			}
		default:
			return nil
		}
	}

	return current
}
package node

import (
	"context"
	"fmt"
	"log"
	"strings"
	"time"

	"github.com/Abraxas-365/craftable/errx"
	"github.com/Abraxas-365/relay/engine"
)

// ActionExecutor ejecuta acciones dentro de workflows
type ActionExecutor struct {
	// Puedes agregar dependencias aqu√≠ si necesitas
}

var _ engine.NodeExecutor = (*ActionExecutor)(nil)

// NewActionExecutor crea una nueva instancia del ejecutor de acciones
func NewActionExecutor() *ActionExecutor {
	return &ActionExecutor{}
}

// Execute ejecuta una acci√≥n seg√∫n su tipo
func (ae *ActionExecutor) Execute(ctx context.Context, node engine.WorkflowNode, input map[string]any) (*engine.NodeResult, error) {
	startTime := time.Now()

	result := &engine.NodeResult{
		NodeID:    node.ID,
		NodeName:  node.Name,
		Timestamp: startTime,
	}

	// Determinar tipo de acci√≥n desde config
	actionType, ok := node.Config["action_type"].(string)
	if !ok {
		result.Success = false
		result.Error = "missing action_type in config"
		result.Duration = time.Since(startTime).Milliseconds()
		return result, engine.ErrInvalidWorkflowNode().WithDetail("reason", "missing action_type")
	}

	// Ejecutar seg√∫n tipo
	var err error
	switch actionType {
	case "console_log":
		err = ae.executeConsoleLog(ctx, node, input, result)
	case "set_context":
		err = ae.executeSetContext(ctx, node, input, result)
	default:
		result.Success = false
		result.Error = fmt.Sprintf("unknown action type: %s", actionType)
		err = engine.ErrInvalidWorkflowNode().WithDetail("action_type", actionType)
	}

	result.Duration = time.Since(startTime).Milliseconds()
	return result, err
}

// executeConsoleLog imprime mensaje en consola
func (ae *ActionExecutor) executeConsoleLog(ctx context.Context, node engine.WorkflowNode, input map[string]any, result *engine.NodeResult) error {
	message, ok := node.Config["message"].(string)
	if !ok {
		result.Success = false
		result.Error = "missing or invalid message"
		return errx.New("missing message in console_log action", errx.TypeValidation)
	}

	// Reemplazar variables del input en el mensaje
	formattedMessage := ae.interpolateVariables(message, input)

	// Imprimir en consola con formato
	log.Printf("üîπ [WORKFLOW ACTION] %s: %s", node.Name, formattedMessage)

	// Tambi√©n imprimir input si est√° configurado
	if printInput, ok := node.Config["print_input"].(bool); ok && printInput {
		log.Printf("   Input: %+v", input)
	}

	result.Success = true
	result.Output = map[string]any{
		"message":   formattedMessage,
		"logged_at": time.Now().Format(time.RFC3339),
	}
	return nil
}

// executeSetContext establece valores en el contexto
func (ae *ActionExecutor) executeSetContext(ctx context.Context, node engine.WorkflowNode, input map[string]any, result *engine.NodeResult) error {
	contextData, ok := node.Config["context"].(map[string]any)
	if !ok {
		result.Success = false
		result.Error = "missing or invalid context data"
		return errx.New("missing context in set_context action", errx.TypeValidation)
	}

	// Interpolar variables
	interpolatedContext := make(map[string]any)
	for key, value := range contextData {
		if strVal, ok := value.(string); ok {
			interpolatedContext[key] = ae.interpolateVariables(strVal, input)
		} else {
			interpolatedContext[key] = value
		}
	}

	log.Printf("üîπ [WORKFLOW ACTION] %s: Setting context keys: %v", node.Name, getKeys(interpolatedContext))

	result.Success = true
	result.Output = map[string]any{
		"context": interpolatedContext,
	}
	return nil
}

// interpolateVariables reemplaza variables tipo {{variable}} en el texto
func (ae *ActionExecutor) interpolateVariables(text string, variables map[string]any) string {
	result := text
	for key, value := range variables {
		placeholder := fmt.Sprintf("{{%s}}", key)
		result = strings.ReplaceAll(result, placeholder, fmt.Sprint(value))
	}
	return result
}

// getKeys obtiene las llaves de un map
func getKeys(m map[string]any) []string {
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	return keys
}

// SupportsType verifica si soporta un tipo de paso
func (ae *ActionExecutor) SupportsType(stepType engine.NodeType) bool {
	return stepType == engine.NodeTypeAction
}

// ValidateConfig valida la configuraci√≥n de una acci√≥n
func (ae *ActionExecutor) ValidateConfig(config map[string]any) error {
	actionType, ok := config["action_type"].(string)
	if !ok {
		return errx.New("action_type is required", errx.TypeValidation)
	}

	switch actionType {
	case "console_log":
		if _, ok := config["message"].(string); !ok {
			return errx.New("message is required for console_log", errx.TypeValidation)
		}
	case "set_context":
		if _, ok := config["context"].(map[string]any); !ok {
			return errx.New("context is required for set_context", errx.TypeValidation)
		}
	case "delay":
		if _, ok := config["duration_ms"]; !ok {
			return errx.New("duration_ms is required for delay", errx.TypeValidation)
		}
	case "response":
		if _, ok := config["text"].(string); !ok {
			return errx.New("text is required for response", errx.TypeValidation)
		}
	default:
		return errx.New("unknown action type", errx.TypeValidation).
			WithDetail("action_type", actionType)
	}

	return nil
}
package delayscheduler

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"time"

	"github.com/Abraxas-365/relay/engine"
	"github.com/go-redis/redis/v8"
	"github.com/google/uuid"
)

const (
	delayedExecutionsKey = "relay:delayed_executions" // Sorted set
	continuationPrefix   = "relay:continuation:"      // Hash keys
	syncDelayThreshold   = 30 * time.Second
)

var _ engine.DelayScheduler = (*RedisDelayScheduler)(nil)

type RedisDelayScheduler struct {
	redis          *redis.Client
	syncThreshold  time.Duration
	onContinuation engine.ContinuationHandler
	workerRunning  bool
	stopChan       chan struct{}
}

func NewRedisDelayScheduler(
	redisClient *redis.Client,
	handler engine.ContinuationHandler,
) *RedisDelayScheduler {
	return &RedisDelayScheduler{
		redis:          redisClient,
		syncThreshold:  syncDelayThreshold,
		onContinuation: handler,
		stopChan:       make(chan struct{}),
	}
}

// Schedule schedules a workflow continuation
func (r *RedisDelayScheduler) Schedule(
	ctx context.Context,
	continuation *engine.WorkflowContinuation,
	delay time.Duration,
) error {
	if continuation.ID == "" {
		continuation.ID = uuid.New().String()
	}

	continuation.ScheduledFor = time.Now().Add(delay)
	continuation.CreatedAt = time.Now()

	// Serialize continuation
	data, err := json.Marshal(continuation)
	if err != nil {
		return fmt.Errorf("failed to marshal continuation: %w", err)
	}

	// Store continuation data
	key := fmt.Sprintf("%s%s", continuationPrefix, continuation.ID)
	if err := r.redis.Set(ctx, key, data, delay+time.Hour).Err(); err != nil {
		return fmt.Errorf("failed to store continuation: %w", err)
	}

	// Add to sorted set with execution timestamp as score
	score := float64(continuation.ScheduledFor.Unix())
	if err := r.redis.ZAdd(ctx, delayedExecutionsKey, &redis.Z{
		Score:  score,
		Member: continuation.ID,
	}).Err(); err != nil {
		return fmt.Errorf("failed to schedule continuation: %w", err)
	}

	log.Printf("‚è∞ Scheduled continuation %s for %v (delay: %v)",
		continuation.ID, continuation.ScheduledFor, delay)

	return nil
}

// ShouldUseAsync determines if delay should be async
func (r *RedisDelayScheduler) ShouldUseAsync(duration time.Duration) bool {
	return duration > r.syncThreshold
}

// StartWorker starts the background worker
func (r *RedisDelayScheduler) StartWorker(ctx context.Context) {
	if r.workerRunning {
		log.Println("‚ö†Ô∏è  Delay scheduler worker already running")
		return
	}

	r.workerRunning = true
	log.Println("üöÄ Starting delay scheduler worker...")

	go r.workerLoop(ctx)
}

// StopWorker stops the background worker
func (r *RedisDelayScheduler) StopWorker() {
	if !r.workerRunning {
		return
	}

	log.Println("üõë Stopping delay scheduler worker...")
	close(r.stopChan)
	r.workerRunning = false
}

func (r *RedisDelayScheduler) workerLoop(ctx context.Context) {
	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			log.Println("‚èπÔ∏è  Delay scheduler worker stopped (context done)")
			return
		case <-r.stopChan:
			log.Println("‚èπÔ∏è  Delay scheduler worker stopped")
			return
		case <-ticker.C:
			if err := r.processDueExecutions(ctx); err != nil {
				log.Printf("‚ùå Error processing due executions: %v", err)
			}
		}
	}
}

func (r *RedisDelayScheduler) processDueExecutions(ctx context.Context) error {
	now := float64(time.Now().Unix())

	// Get jobs due for execution
	jobs, err := r.redis.ZRangeByScore(ctx, delayedExecutionsKey, &redis.ZRangeBy{
		Min:   "-inf",
		Max:   fmt.Sprintf("%f", now),
		Count: 10,
	}).Result()

	if err != nil {
		return fmt.Errorf("failed to fetch due executions: %w", err)
	}

	if len(jobs) == 0 {
		return nil
	}

	log.Printf("üìã Found %d due executions to process", len(jobs))

	for _, jobID := range jobs {
		// Try to claim the job atomically
		removed, err := r.redis.ZRem(ctx, delayedExecutionsKey, jobID).Result()
		if err != nil || removed == 0 {
			// Another worker claimed it or error occurred
			continue
		}

		// Execute the job
		go r.executeJob(context.Background(), jobID)
	}

	return nil
}

func (r *RedisDelayScheduler) executeJob(ctx context.Context, jobID string) {
	log.Printf("‚ñ∂Ô∏è  Executing delayed job: %s", jobID)

	// Retrieve continuation data
	key := fmt.Sprintf("%s%s", continuationPrefix, jobID)
	data, err := r.redis.Get(ctx, key).Result()
	if err != nil {
		log.Printf("‚ùå Failed to retrieve continuation %s: %v", jobID, err)
		return
	}

	// Deserialize continuation
	var continuation engine.WorkflowContinuation
	if err := json.Unmarshal([]byte(data), &continuation); err != nil {
		log.Printf("‚ùå Failed to unmarshal continuation %s: %v", jobID, err)
		return
	}

	// Execute continuation handler
	if r.onContinuation != nil {
		if err := r.onContinuation(ctx, &continuation); err != nil {
			log.Printf("‚ùå Failed to execute continuation %s: %v", jobID, err)
			return
		}
	}

	// Clean up
	r.redis.Del(ctx, key)
	log.Printf("‚úÖ Completed delayed job: %s", jobID)
}

// GetPendingCount returns the number of pending delayed executions
func (r *RedisDelayScheduler) GetPendingCount(ctx context.Context) (int64, error) {
	return r.redis.ZCard(ctx, delayedExecutionsKey).Result()
}

// GetContinuation retrieves a continuation by ID
func (r *RedisDelayScheduler) GetContinuation(ctx context.Context, id string) (*engine.WorkflowContinuation, error) {
	key := fmt.Sprintf("%s%s", continuationPrefix, id)
	data, err := r.redis.Get(ctx, key).Result()
	if err != nil {
		return nil, err
	}

	var continuation engine.WorkflowContinuation
	if err := json.Unmarshal([]byte(data), &continuation); err != nil {
		return nil, err
	}

	return &continuation, nil
}

// Cancel cancels a scheduled continuation
func (r *RedisDelayScheduler) Cancel(ctx context.Context, id string) error {
	// Remove from sorted set
	if err := r.redis.ZRem(ctx, delayedExecutionsKey, id).Err(); err != nil {
		return err
	}

	// Delete continuation data
	key := fmt.Sprintf("%s%s", continuationPrefix, id)
	return r.redis.Del(ctx, key).Err()
}

package engine

import (
	"time"

	"github.com/Abraxas-365/relay/pkg/kernel"
	"slices"
)

// ============================================================================
// Workflow Input (NEW - Primary input for workflows)
// ============================================================================

// WorkflowInput represents generic input data for workflow execution
type WorkflowInput struct {
	TriggerData map[string]any  `json:"trigger_data"` // Data from trigger
	TenantID    kernel.TenantID `json:"tenant_id"`
	Metadata    map[string]any  `json:"metadata,omitempty"`
}

// ============================================================================
// Message Entity (OPTIONAL - Only for channel integrations)
// ============================================================================

// Message represents a channel message (optional, only used by channel triggers)
type Message struct {
	ID        kernel.MessageID `db:"id" json:"id"`
	TenantID  kernel.TenantID  `db:"tenant_id" json:"tenant_id"`
	ChannelID kernel.ChannelID `db:"channel_id" json:"channel_id"`
	SenderID  string           `db:"sender_id" json:"sender_id"`
	Content   MessageContent   `db:"content" json:"content"`
	Context   map[string]any   `db:"context" json:"context"`
	CreatedAt time.Time        `db:"created_at" json:"created_at"`
}

type MessageContent struct {
	Type        string         `json:"type"`
	Text        string         `json:"text,omitempty"`
	Attachments []string       `json:"attachments,omitempty"`
	Metadata    map[string]any `json:"metadata,omitempty"`
}

// Helper methods for Message
func (m *Message) IsValid() bool {
	return !m.ID.IsEmpty() && !m.ChannelID.IsEmpty() && m.SenderID != ""
}

func (m *Message) HasTextContent() bool {
	return m.Content.Type == "text" && m.Content.Text != ""
}

// ============================================================================
// Workflow Entity
// ============================================================================

type Workflow struct {
	ID          kernel.WorkflowID `db:"id" json:"id"`
	TenantID    kernel.TenantID   `db:"tenant_id" json:"tenant_id"`
	Name        string            `db:"name" json:"name"`
	Description string            `db:"description" json:"description"`
	Trigger     WorkflowTrigger   `db:"trigger" json:"trigger"`
	Nodes       []WorkflowNode    `db:"nodes" json:"nodes"`
	IsActive    bool              `db:"is_active" json:"is_active"`
	CreatedAt   time.Time         `db:"created_at" json:"created_at"`
	UpdatedAt   time.Time         `db:"updated_at" json:"updated_at"`
}

// WorkflowTrigger defines when workflow executes
type WorkflowTrigger struct {
	Type    TriggerType    `json:"type"`
	Config  map[string]any `json:"config,omitempty"`
	Filters map[string]any `json:"filters,omitempty"`
}

// TriggerType defines trigger types
type TriggerType string

const (
	TriggerTypeWebhook        TriggerType = "WEBHOOK"
	TriggerTypeSchedule       TriggerType = "SCHEDULE"
	TriggerTypeManual         TriggerType = "MANUAL"
	TriggerTypeChannelWebhook TriggerType = "CHANNEL_WEBHOOK" // For channel integrations
)

// WorkflowNode represents a workflow step
type WorkflowNode struct {
	ID        string         `json:"id"`
	Name      string         `json:"name"`
	Type      NodeType       `json:"type"`
	Config    map[string]any `json:"config"`
	OnSuccess string         `json:"on_success,omitempty"`
	OnFailure string         `json:"on_failure,omitempty"`
	Timeout   *int           `json:"timeout,omitempty"`
}

// NodeType defines node types
type NodeType string

const (
	NodeTypeCondition   NodeType = "CONDITION"
	NodeTypeAction      NodeType = "ACTION"
	NodeTypeDelay       NodeType = "DELAY"
	NodeTypeSwitch      NodeType = "SWITCH"
	NodeTypeTransform   NodeType = "TRANSFORM"
	NodeTypeHTTP        NodeType = "HTTP"
	NodeTypeLoop        NodeType = "LOOP"
	NodeTypeValidate    NodeType = "VALIDATE"
	NodeTypeAIAgent     NodeType = "AI_AGENT"
	NodeTypeSendMessage NodeType = "SEND_MESSAGE"
)

// ============================================================================
// Execution Result
// ============================================================================

type ExecutionResult struct {
	Success       bool           `json:"success"`
	Output        map[string]any `json:"output,omitempty"`
	Error         error          `json:"-"`
	ErrorMessage  string         `json:"error,omitempty"`
	ExecutedNodes []NodeResult   `json:"executed_nodes,omitempty"`
}

type NodeResult struct {
	NodeID    string         `json:"node_id"`
	NodeName  string         `json:"node_name"`
	Success   bool           `json:"success"`
	Output    map[string]any `json:"output,omitempty"`
	Error     string         `json:"error,omitempty"`
	Duration  int64          `json:"duration_ms"`
	Timestamp time.Time      `json:"timestamp"`
}

// ============================================================================
// Domain Methods - Workflow
// ============================================================================

func (w *Workflow) IsValid() bool {
	return w.Name != "" && len(w.Nodes) > 0 && !w.TenantID.IsEmpty()
}

func (w *Workflow) Activate() {
	w.IsActive = true
	w.UpdatedAt = time.Now()
}

func (w *Workflow) Deactivate() {
	w.IsActive = false
	w.UpdatedAt = time.Now()
}

func (w *Workflow) UpdateDetails(name, description string) {
	if name != "" {
		w.Name = name
	}
	if description != "" {
		w.Description = description
	}
	w.UpdatedAt = time.Now()
}

func (w *Workflow) UpdateNodes(nodes []WorkflowNode) {
	w.Nodes = nodes
	w.UpdatedAt = time.Now()
}

func (w *Workflow) GetNodeByID(nodeID string) *WorkflowNode {
	for i := range w.Nodes {
		if w.Nodes[i].ID == nodeID {
			return &w.Nodes[i]
		}
	}
	return nil
}

func (w *Workflow) MatchesTrigger(trigger WorkflowTrigger) bool {
	if w.Trigger.Type != trigger.Type {
		return false
	}

	// Match filters if present
	if len(w.Trigger.Filters) > 0 && len(trigger.Filters) > 0 {
		for key, expectedVal := range w.Trigger.Filters {
			if actualVal, ok := trigger.Filters[key]; ok {
				// Handle array matching (e.g., channel_ids)
				if key == "channel_ids" {
					expectedIDs, ok1 := expectedVal.([]string)
					actualIDs, ok2 := actualVal.([]string)
					if ok1 && ok2 {
						for _, eid := range expectedIDs {
							if slices.Contains(actualIDs, eid) {
								return true
							}
						}
						return false
					}
				}
				// Simple equality
				if expectedVal != actualVal {
					return false
				}
			}
		}
	}

	return true
}

package triggerhandler

import (
	"context"
	"fmt"
	"log"

	"github.com/Abraxas-365/relay/engine"
	"github.com/Abraxas-365/relay/pkg/kernel"
)

// TriggerHandler handles workflow triggers
type TriggerHandler struct {
	workflowRepo     engine.WorkflowRepository
	workflowExecutor engine.WorkflowExecutor
}

func NewTriggerHandler(
	workflowRepo engine.WorkflowRepository,
	workflowExecutor engine.WorkflowExecutor,
) *TriggerHandler {
	return &TriggerHandler{
		workflowRepo:     workflowRepo,
		workflowExecutor: workflowExecutor,
	}
}

// HandleWebhookTrigger handles generic webhook triggers
func (h *TriggerHandler) HandleWebhookTrigger(
	ctx context.Context,
	tenantID kernel.TenantID,
	triggerData map[string]any,
) error {
	return h.executeTrigger(ctx, engine.TriggerTypeWebhook, tenantID, triggerData, nil)
}

// HandleChannelWebhookTrigger handles channel message triggers
func (h *TriggerHandler) HandleChannelWebhookTrigger(
	ctx context.Context,
	tenantID kernel.TenantID,
	channelID kernel.ChannelID,
	triggerData map[string]any,
) error {
	filters := map[string]any{
		"channel_ids": []string{channelID.String()},
	}
	return h.executeTrigger(ctx, engine.TriggerTypeChannelWebhook, tenantID, triggerData, filters)
}

// HandleScheduleTrigger handles scheduled triggers
func (h *TriggerHandler) HandleScheduleTrigger(
	ctx context.Context,
	tenantID kernel.TenantID,
	scheduleID string,
	triggerData map[string]any,
) error {
	filters := map[string]any{
		"schedule_id": scheduleID,
	}
	return h.executeTrigger(ctx, engine.TriggerTypeSchedule, tenantID, triggerData, filters)
}

// HandleManualTrigger handles manual workflow execution
func (h *TriggerHandler) HandleManualTrigger(
	ctx context.Context,
	workflowID kernel.WorkflowID,
	tenantID kernel.TenantID,
	triggerData map[string]any,
) error {
	workflow, err := h.workflowRepo.FindByID(ctx, workflowID)
	if err != nil {
		return fmt.Errorf("workflow not found: %w", err)
	}

	if workflow.TenantID != tenantID {
		return fmt.Errorf("workflow does not belong to tenant")
	}

	input := engine.WorkflowInput{
		TriggerData: triggerData,
		TenantID:    tenantID,
		Metadata: map[string]any{
			"trigger_type": engine.TriggerTypeManual,
		},
	}

	result, err := h.workflowExecutor.Execute(ctx, *workflow, input)
	if err != nil {
		return fmt.Errorf("workflow execution failed: %w", err)
	}

	log.Printf("‚úÖ Manual workflow executed: %s (success=%v)", workflow.Name, result.Success)
	return nil
}

// executeTrigger is the core trigger execution logic
func (h *TriggerHandler) executeTrigger(
	ctx context.Context,
	triggerType engine.TriggerType,
	tenantID kernel.TenantID,
	triggerData map[string]any,
	filters map[string]any,
) error {
	log.Printf("üîî Handling trigger: type=%s, tenant=%s", triggerType, tenantID.String())

	// Build trigger to match
	trigger := engine.WorkflowTrigger{
		Type:    triggerType,
		Filters: filters,
	}

	// Find matching workflows
	workflows, err := h.workflowRepo.FindActiveByTrigger(ctx, trigger, tenantID)
	if err != nil {
		return fmt.Errorf("failed to find workflows: %w", err)
	}

	if len(workflows) == 0 {
		log.Printf("‚ÑπÔ∏è  No active workflows found for trigger type: %s", triggerType)
		return nil
	}

	log.Printf("üìã Found %d matching workflow(s)", len(workflows))

	// Execute each matching workflow (async to not block)
	for _, workflow := range workflows {
		go func(wf *engine.Workflow) {
			log.Printf("‚ñ∂Ô∏è  Executing workflow: %s", wf.Name)

			input := engine.WorkflowInput{
				TriggerData: triggerData,
				TenantID:    tenantID,
				Metadata: map[string]any{
					"trigger_type": triggerType,
					"workflow_id":  wf.ID.String(),
				},
			}

			result, err := h.workflowExecutor.Execute(ctx, *wf, input)
			if err != nil {
				log.Printf("‚ùå Workflow %s execution failed: %v", wf.Name, err)
				return
			}

			log.Printf("‚úÖ Workflow %s executed (success=%v, nodes=%d)",
				wf.Name, result.Success, len(result.ExecutedNodes))
		}(workflow)
	}

	return nil
}
package engine

import (
	"context"
	"fmt"
	"log"
	"reflect"
	"regexp"
	"strings"

	"github.com/google/cel-go/cel"
	"github.com/google/cel-go/common/types/ref"
)

// ExpressionEvaluator defines the interface for evaluating expressions within workflow data.
type ExpressionEvaluator interface {
	// Evaluate recursively traverses a data structure (like a step's config)
	// and replaces any expressions (e.g., {{step_1.output.userId}}) with their
	// evaluated values from the provided context.
	Evaluate(ctx context.Context, data any, context map[string]any) (any, error)
}

// celEvaluator is an implementation of ExpressionEvaluator using CEL-Go.
type celEvaluator struct {
	expressionRegex *regexp.Regexp
}

// NewCelEvaluator creates a new expression evaluator.
func NewCelEvaluator() ExpressionEvaluator {
	return &celEvaluator{
		// Regex to find expressions like {{ expression }}
		expressionRegex: regexp.MustCompile(`\{\{([^}]+)\}\}`),
	}
}

func (e *celEvaluator) Evaluate(ctx context.Context, data any, context map[string]any) (any, error) {
	return e.evaluateRecursive(reflect.ValueOf(data), context)
}

// evaluateRecursive is the core evaluation logic.
func (e *celEvaluator) evaluateRecursive(val reflect.Value, context map[string]any) (any, error) {
	// Handle pointers and interfaces
	if val.Kind() == reflect.Ptr || val.Kind() == reflect.Interface {
		if val.IsNil() {
			return nil, nil
		}
		val = val.Elem()
	}

	switch val.Kind() {
	case reflect.String:
		// This is where we find and replace expressions
		return e.evaluateString(val.String(), context)

	case reflect.Map:
		newMap := make(map[string]any)
		for _, key := range val.MapKeys() {
			// Evaluate the value of each map entry
			evaluatedVal, err := e.evaluateRecursive(val.MapIndex(key), context)
			if err != nil {
				return nil, err
			}
			newMap[key.String()] = evaluatedVal
		}
		return newMap, nil

	case reflect.Slice:
		newSlice := make([]any, val.Len())
		for i := 0; i < val.Len(); i++ {
			// Evaluate each item in the slice
			evaluatedItem, err := e.evaluateRecursive(val.Index(i), context)
			if err != nil {
				return nil, err
			}
			newSlice[i] = evaluatedItem
		}
		return newSlice, nil

	default:
		// For other types (int, bool, etc.), return the original value
		return val.Interface(), nil
	}
}

// evaluateString finds and evaluates all expressions in a single string.
func (e *celEvaluator) evaluateString(s string, context map[string]any) (any, error) {
	matches := e.expressionRegex.FindStringSubmatch(s)

	// If the string is *only* an expression (e.g., "{{step_1.output}}"),
	// return the evaluated type directly (e.g., a map or a number).
	if len(matches) > 0 && s == matches[0] {
		expr := strings.TrimSpace(matches[1])

		// ‚úÖ Try simple path lookup first before CEL
		if value, found := getNestedValue(context, expr); found {
			log.Printf("‚úÖ Resolved '%s' via simple path lookup: %v", expr, value)
			return value, nil
		}

		return e.evaluateCEL(expr, context)
	}

	// Otherwise, replace all occurrences of expressions inside the string.
	var evalError error
	resultString := e.expressionRegex.ReplaceAllStringFunc(s, func(match string) string {
		expr := strings.TrimSpace(e.expressionRegex.FindStringSubmatch(match)[1])

		// Try simple path lookup first
		if value, found := getNestedValue(context, expr); found {
			return fmt.Sprintf("%v", value)
		}

		evaluatedVal, err := e.evaluateCEL(expr, context)
		if err != nil {
			evalError = err
			return match // Return original on error
		}
		return fmt.Sprintf("%v", evaluatedVal)
	})

	if evalError != nil {
		return nil, evalError
	}

	return resultString, nil
}

// evaluateCEL compiles and runs a single CEL expression.
func (e *celEvaluator) evaluateCEL(expression string, context map[string]any) (any, error) {
	log.Printf("üîç Evaluating CEL expression: '%s'", expression)
	log.Printf("   Available context keys: %v", getContextKeys(context))

	// ‚úÖ FIX: Declare all context variables to CEL
	var envOptions []cel.EnvOption

	// Declare each top-level context key as a CEL variable
	for key := range context {
		envOptions = append(envOptions, cel.Variable(key, cel.DynType))
	}

	env, err := cel.NewEnv(envOptions...)
	if err != nil {
		return nil, fmt.Errorf("failed to create CEL environment: %w", err)
	}

	parsed, issues := env.Parse(expression)
	if issues != nil && issues.Err() != nil {
		log.Printf("‚ùå CEL parse error for '%s': %v", expression, issues.Err())
		return nil, fmt.Errorf("failed to parse expression '%s': %w", expression, issues.Err())
	}

	checked, issues := env.Check(parsed)
	if issues != nil && issues.Err() != nil {
		log.Printf("‚ö†Ô∏è  CEL check warning for '%s': %v", expression, issues.Err())
		// Don't fail on check errors for dynamic data
	}

	prg, err := env.Program(checked)
	if err != nil {
		log.Printf("‚ùå CEL program error for '%s': %v", expression, err)
		return nil, fmt.Errorf("failed to create program for '%s': %w", expression, err)
	}

	out, _, err := prg.Eval(context)
	if err != nil {
		log.Printf("‚ùå CEL eval error for '%s': %v", expression, err)
		log.Printf("   Context: %+v", context)
		return nil, fmt.Errorf("failed to evaluate expression '%s': %w", expression, err)
	}

	// Convert CEL type to native Go type
	nativeValue, err := e.convertToNative(out)
	if err != nil {
		return nil, fmt.Errorf("failed to convert CEL result for '%s': %w", expression, err)
	}

	log.Printf("‚úÖ CEL result for '%s': %v", expression, nativeValue)
	return nativeValue, nil
}

// convertToNative converts a CEL-Go `ref.Val` to a native Go type.
func (e *celEvaluator) convertToNative(val ref.Val) (any, error) {
	if val == nil || val.Value() == nil {
		return nil, nil
	}
	native, err := val.ConvertToNative(reflect.TypeOf(map[string]any{}))
	if err == nil {
		return native, nil // Successfully converted to map/slice/etc.
	}
	return val.Value(), nil // Fallback to the primitive value (int, string, bool)
}

// ‚úÖ ADD: Simple nested value lookup (fallback if CEL fails)
func getNestedValue(data map[string]any, path string) (any, bool) {
	parts := strings.Split(path, ".")
	current := any(data)

	for _, part := range parts {
		switch v := current.(type) {
		case map[string]any:
			if val, ok := v[part]; ok {
				current = val
			} else {
				return nil, false
			}
		default:
			return nil, false
		}
	}

	return current, true
}

// ‚úÖ ADD: Helper to get context keys for logging
func getContextKeys(m map[string]any) []string {
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	return keys
}

package engine

import (
	"context"
	"time"

	"github.com/Abraxas-365/relay/pkg/kernel"
)

// ============================================================================
// Repository Interfaces
// ============================================================================

// WorkflowRepository persistence for workflows
type WorkflowRepository interface {
	Save(ctx context.Context, wf Workflow) error
	FindByID(ctx context.Context, id kernel.WorkflowID) (*Workflow, error)
	FindByName(ctx context.Context, name string, tenantID kernel.TenantID) (*Workflow, error)
	Delete(ctx context.Context, id kernel.WorkflowID, tenantID kernel.TenantID) error
	ExistsByName(ctx context.Context, name string, tenantID kernel.TenantID) (bool, error)

	FindByTenant(ctx context.Context, tenantID kernel.TenantID) ([]*Workflow, error)
	FindActive(ctx context.Context, tenantID kernel.TenantID) ([]*Workflow, error)
	FindByTriggerType(ctx context.Context, triggerType TriggerType, tenantID kernel.TenantID) ([]*Workflow, error)
	FindActiveByTrigger(ctx context.Context, trigger WorkflowTrigger, tenantID kernel.TenantID) ([]*Workflow, error)

	List(ctx context.Context, req WorkflowListRequest) (WorkflowListResponse, error)
	BulkUpdateStatus(ctx context.Context, ids []kernel.WorkflowID, tenantID kernel.TenantID, isActive bool) error
}

// ============================================================================
// Executor Interfaces
// ============================================================================

// WorkflowExecutor executes workflows
type WorkflowExecutor interface {
	// Execute workflow with generic input
	Execute(ctx context.Context, workflow Workflow, input WorkflowInput) (*ExecutionResult, error)

	// Resume workflow from specific node (for delay continuation)
	ResumeFromNode(
		ctx context.Context,
		workflow Workflow,
		input WorkflowInput,
		startNodeID string,
		nodeContext map[string]any,
	) (*ExecutionResult, error)

	// Validate workflow structure
	ValidateWorkflow(ctx context.Context, workflow Workflow) error
}

// NodeExecutor executes specific workflow nodes
type NodeExecutor interface {
	Execute(ctx context.Context, node WorkflowNode, input map[string]any) (*NodeResult, error)
	SupportsType(nodeType NodeType) bool
	ValidateConfig(config map[string]any) error
}

// ============================================================================
// Delay Scheduler Interface
// ============================================================================

// WorkflowContinuation stores state for resuming workflow execution
type WorkflowContinuation struct {
	ID           string         `json:"id"`
	WorkflowID   string         `json:"workflow_id"`
	TenantID     string         `json:"tenant_id"`
	NodeID       string         `json:"node_id"`
	NextNodeID   string         `json:"next_node_id"`
	NodeContext  map[string]any `json:"node_context"`
	ScheduledFor time.Time      `json:"scheduled_for"`
	CreatedAt    time.Time      `json:"created_at"`
}

// ContinuationHandler is called when delayed execution is ready
type ContinuationHandler func(ctx context.Context, continuation *WorkflowContinuation) error

// DelayScheduler manages delayed workflow executions
type DelayScheduler interface {
	Schedule(ctx context.Context, continuation *WorkflowContinuation, delay time.Duration) error
	ShouldUseAsync(duration time.Duration) bool
	StartWorker(ctx context.Context)
	StopWorker()
	GetPendingCount(ctx context.Context) (int64, error)
	GetContinuation(ctx context.Context, id string) (*WorkflowContinuation, error)
	Cancel(ctx context.Context, id string) error
}

type WorkflowScheduleRepository interface {
	Save(ctx context.Context, schedule WorkflowSchedule) error
	Update(ctx context.Context, schedule WorkflowSchedule) error
	FindByID(ctx context.Context, id string) (*WorkflowSchedule, error)
	FindByWorkflow(ctx context.Context, workflowID kernel.WorkflowID) ([]*WorkflowSchedule, error)
	FindDue(ctx context.Context, before time.Time) ([]*WorkflowSchedule, error)
	Delete(ctx context.Context, id string) error

	// List all schedules for a tenant
	FindByTenant(ctx context.Context, tenantID kernel.TenantID) ([]*WorkflowSchedule, error)
	CountByWorkflow(ctx context.Context, workflowID kernel.WorkflowID) (int, error)
}
package engine

import (
	"github.com/Abraxas-365/craftable/storex"
	"github.com/Abraxas-365/relay/pkg/kernel"
)

// ============================================================================
// Workflow DTOs
// ============================================================================

type CreateWorkflowRequest struct {
	TenantID    kernel.TenantID `json:"tenant_id" validate:"required"`
	Name        string          `json:"name" validate:"required,min=2"`
	Description string          `json:"description,omitempty"`
	Trigger     WorkflowTrigger `json:"trigger" validate:"required"`
	Nodes       []WorkflowNode  `json:"nodes" validate:"required,min=1"`
}

type UpdateWorkflowRequest struct {
	Name        *string          `json:"name,omitempty"`
	Description *string          `json:"description,omitempty"`
	Trigger     *WorkflowTrigger `json:"trigger,omitempty"`
	Nodes       *[]WorkflowNode  `json:"nodes,omitempty"`
	IsActive    *bool            `json:"is_active,omitempty"`
}

type ExecuteWorkflowRequest struct {
	WorkflowID  kernel.WorkflowID `json:"workflow_id" validate:"required"`
	TriggerData map[string]any    `json:"trigger_data,omitempty"`
	Metadata    map[string]any    `json:"metadata,omitempty"`
}

type WorkflowResponse struct {
	Workflow Workflow `json:"workflow"`
}

type WorkflowListRequest struct {
	storex.PaginationOptions
	TenantID kernel.TenantID `json:"tenant_id" validate:"required"`
	IsActive *bool           `json:"is_active,omitempty"`
	Search   string          `json:"search,omitempty"`
}

func (wlr WorkflowListRequest) GetOffset() int {
	return (wlr.Page - 1) * wlr.PageSize
}

type WorkflowListResponse = storex.Paginated[Workflow]

type WorkflowExecutionResponse struct {
	WorkflowID    kernel.WorkflowID `json:"workflow_id"`
	Success       bool              `json:"success"`
	Output        map[string]any    `json:"output,omitempty"`
	Error         string            `json:"error,omitempty"`
	ExecutedNodes []NodeResult      `json:"executed_nodes,omitempty"`
}

// ============================================================================
// Validation DTOs
// ============================================================================

type ValidateWorkflowRequest struct {
	Trigger WorkflowTrigger `json:"trigger" validate:"required"`
	Nodes   []WorkflowNode  `json:"nodes" validate:"required,min=1"`
}

type ValidateWorkflowResponse struct {
	IsValid  bool     `json:"is_valid"`
	Errors   []string `json:"errors,omitempty"`
	Warnings []string `json:"warnings,omitempty"`
}

// ============================================================================
// Bulk Operation DTOs
// ============================================================================

type BulkWorkflowOperationRequest struct {
	TenantID    kernel.TenantID     `json:"tenant_id" validate:"required"`
	WorkflowIDs []kernel.WorkflowID `json:"workflow_ids" validate:"required,min=1"`
	Operation   string              `json:"operation" validate:"required,oneof=activate deactivate delete"`
}

type BulkWorkflowOperationResponse struct {
	Successful []kernel.WorkflowID          `json:"successful"`
	Failed     map[kernel.WorkflowID]string `json:"failed"`
	Total      int                          `json:"total"`
}

// ============================================================================
// Simple DTOs
// ============================================================================

type WorkflowDetailsDTO struct {
	ID        kernel.WorkflowID `json:"id"`
	Name      string            `json:"name"`
	IsActive  bool              `json:"is_active"`
	NodeCount int               `json:"node_count"`
}

func (w *Workflow) ToDTO() WorkflowDetailsDTO {
	return WorkflowDetailsDTO{
		ID:        w.ID,
		Name:      w.Name,
		IsActive:  w.IsActive,
		NodeCount: len(w.Nodes),
	}
}
package engine

import (
	"github.com/Abraxas-365/relay/pkg/kernel"
	"time"
)

type WorkflowSchedule struct {
	ID         string            `db:"id" json:"id"`
	TenantID   kernel.TenantID   `db:"tenant_id" json:"tenant_id"`
	WorkflowID kernel.WorkflowID `db:"workflow_id" json:"workflow_id"`

	// Schedule config
	ScheduleType    ScheduleType `db:"schedule_type" json:"schedule_type"`
	CronExpression  *string      `db:"cron_expression" json:"cron_expression,omitempty"`
	IntervalSeconds *int         `db:"interval_seconds" json:"interval_seconds,omitempty"`
	ScheduledAt     *time.Time   `db:"scheduled_at" json:"scheduled_at,omitempty"`

	// Status
	IsActive  bool       `db:"is_active" json:"is_active"`
	LastRunAt *time.Time `db:"last_run_at" json:"last_run_at,omitempty"`
	NextRunAt *time.Time `db:"next_run_at" json:"next_run_at,omitempty"`
	RunCount  int        `db:"run_count" json:"run_count"`

	// Metadata
	Timezone string         `db:"timezone" json:"timezone"`
	Metadata map[string]any `db:"metadata" json:"metadata,omitempty"`

	CreatedAt time.Time `db:"created_at" json:"created_at"`
	UpdatedAt time.Time `db:"updated_at" json:"updated_at"`
}

type ScheduleType string

const (
	ScheduleTypeCron     ScheduleType = "cron"     // Cron expression
	ScheduleTypeInterval ScheduleType = "interval" // Fixed interval
	ScheduleTypeOnce     ScheduleType = "once"     // One-time execution
)

// Domain methods
func (s *WorkflowSchedule) IsValid() bool {
	switch s.ScheduleType {
	case ScheduleTypeCron:
		return s.CronExpression != nil && *s.CronExpression != ""
	case ScheduleTypeInterval:
		return s.IntervalSeconds != nil && *s.IntervalSeconds > 0
	case ScheduleTypeOnce:
		return s.ScheduledAt != nil
	default:
		return false
	}
}

func (s *WorkflowSchedule) ShouldRun(now time.Time) bool {
	if !s.IsActive {
		return false
	}
	if s.NextRunAt == nil {
		return false
	}
	return now.After(*s.NextRunAt) || now.Equal(*s.NextRunAt)
}

func (s *WorkflowSchedule) MarkExecuted(now time.Time) {
	s.LastRunAt = &now
	s.RunCount++

	// For one-time schedules, deactivate after execution
	if s.ScheduleType == ScheduleTypeOnce {
		s.IsActive = false
		s.NextRunAt = nil
	}
}
package engine

import (
	"net/http"

	"github.com/Abraxas-365/craftable/errx"
)

var ErrRegistry = errx.NewRegistry("ENGINE")

var (
	// Workflow errors
	CodeWorkflowNotFound        = ErrRegistry.Register("WORKFLOW_NOT_FOUND", errx.TypeNotFound, http.StatusNotFound, "Workflow not found")
	CodeWorkflowAlreadyExists   = ErrRegistry.Register("WORKFLOW_ALREADY_EXISTS", errx.TypeConflict, http.StatusConflict, "Workflow already exists")
	CodeInvalidWorkflowConfig   = ErrRegistry.Register("INVALID_WORKFLOW_CONFIG", errx.TypeValidation, http.StatusBadRequest, "Invalid workflow configuration")
	CodeWorkflowInactive        = ErrRegistry.Register("WORKFLOW_INACTIVE", errx.TypeBusiness, http.StatusForbidden, "Workflow is inactive")
	CodeWorkflowExecutionFailed = ErrRegistry.Register("WORKFLOW_EXECUTION_FAILED", errx.TypeInternal, http.StatusInternalServerError, "Workflow execution failed")
	CodeInvalidWorkflowNode     = ErrRegistry.Register("INVALID_WORKFLOW_NODE", errx.TypeValidation, http.StatusBadRequest, "Invalid workflow node")
	CodeNodeNotFound            = ErrRegistry.Register("NODE_NOT_FOUND", errx.TypeNotFound, http.StatusNotFound, "Node not found")
	CodeCyclicWorkflow          = ErrRegistry.Register("CYCLIC_WORKFLOW", errx.TypeValidation, http.StatusBadRequest, "Workflow has cycles")

	// Trigger errors
	CodeInvalidTrigger     = ErrRegistry.Register("INVALID_TRIGGER", errx.TypeValidation, http.StatusBadRequest, "Invalid trigger")
	CodeNoMatchingWorkflow = ErrRegistry.Register("NO_MATCHING_WORKFLOW", errx.TypeBusiness, http.StatusNotFound, "No matching workflow found")

	// Execution errors
	CodeExecutionTimeout    = ErrRegistry.Register("EXECUTION_TIMEOUT", errx.TypeInternal, http.StatusRequestTimeout, "Execution timeout")
	CodeNodeExecutionFailed = ErrRegistry.Register("NODE_EXECUTION_FAILED", errx.TypeInternal, http.StatusInternalServerError, "Node execution failed")

	// ‚úÖ Schedule errors
	CodeScheduleNotFound        = ErrRegistry.Register("SCHEDULE_NOT_FOUND", errx.TypeNotFound, http.StatusNotFound, "Schedule not found")
	CodeScheduleAlreadyExists   = ErrRegistry.Register("SCHEDULE_ALREADY_EXISTS", errx.TypeConflict, http.StatusConflict, "Schedule already exists")
	CodeInvalidScheduleConfig   = ErrRegistry.Register("INVALID_SCHEDULE_CONFIG", errx.TypeValidation, http.StatusBadRequest, "Invalid schedule configuration")
	CodeInvalidCronExpression   = ErrRegistry.Register("INVALID_CRON_EXPRESSION", errx.TypeValidation, http.StatusBadRequest, "Invalid cron expression")
	CodeInvalidInterval         = ErrRegistry.Register("INVALID_INTERVAL", errx.TypeValidation, http.StatusBadRequest, "Invalid interval")
	CodeScheduleInPast          = ErrRegistry.Register("SCHEDULE_IN_PAST", errx.TypeValidation, http.StatusBadRequest, "Scheduled time is in the past")
	CodeScheduleConflict        = ErrRegistry.Register("SCHEDULE_CONFLICT", errx.TypeConflict, http.StatusConflict, "Schedule conflicts with existing schedule")
	CodeScheduleExecutionFailed = ErrRegistry.Register("SCHEDULE_EXECUTION_FAILED", errx.TypeInternal, http.StatusInternalServerError, "Schedule execution failed")
	CodeScheduleNotActive       = ErrRegistry.Register("SCHEDULE_NOT_ACTIVE", errx.TypeBusiness, http.StatusForbidden, "Schedule is not active")
	CodeTooManySchedules        = ErrRegistry.Register("TOO_MANY_SCHEDULES", errx.TypeBusiness, http.StatusTooManyRequests, "Too many schedules for workflow")
)

// ============================================================================
// Workflow Error Constructors
// ============================================================================

func ErrWorkflowNotFound() *errx.Error {
	return ErrRegistry.New(CodeWorkflowNotFound)
}

func ErrWorkflowAlreadyExists() *errx.Error {
	return ErrRegistry.New(CodeWorkflowAlreadyExists)
}

func ErrInvalidWorkflowConfig() *errx.Error {
	return ErrRegistry.New(CodeInvalidWorkflowConfig)
}

func ErrWorkflowInactive() *errx.Error {
	return ErrRegistry.New(CodeWorkflowInactive)
}

func ErrWorkflowExecutionFailed() *errx.Error {
	return ErrRegistry.New(CodeWorkflowExecutionFailed)
}

func ErrInvalidWorkflowNode() *errx.Error {
	return ErrRegistry.New(CodeInvalidWorkflowNode)
}

func ErrNodeNotFound() *errx.Error {
	return ErrRegistry.New(CodeNodeNotFound)
}

func ErrCyclicWorkflow() *errx.Error {
	return ErrRegistry.New(CodeCyclicWorkflow)
}

// ============================================================================
// Trigger Error Constructors
// ============================================================================

func ErrInvalidTrigger() *errx.Error {
	return ErrRegistry.New(CodeInvalidTrigger)
}

func ErrNoMatchingWorkflow() *errx.Error {
	return ErrRegistry.New(CodeNoMatchingWorkflow)
}

// ============================================================================
// Execution Error Constructors
// ============================================================================

func ErrExecutionTimeout() *errx.Error {
	return ErrRegistry.New(CodeExecutionTimeout)
}

func ErrNodeExecutionFailed() *errx.Error {
	return ErrRegistry.New(CodeNodeExecutionFailed)
}

// ============================================================================
// ‚úÖ Schedule Error Constructors
// ============================================================================

func ErrScheduleNotFound() *errx.Error {
	return ErrRegistry.New(CodeScheduleNotFound)
}

func ErrScheduleAlreadyExists() *errx.Error {
	return ErrRegistry.New(CodeScheduleAlreadyExists)
}

func ErrInvalidScheduleConfig() *errx.Error {
	return ErrRegistry.New(CodeInvalidScheduleConfig)
}

func ErrInvalidCronExpression() *errx.Error {
	return ErrRegistry.New(CodeInvalidCronExpression)
}

func ErrInvalidInterval() *errx.Error {
	return ErrRegistry.New(CodeInvalidInterval)
}

func ErrScheduleInPast() *errx.Error {
	return ErrRegistry.New(CodeScheduleInPast)
}

func ErrScheduleConflict() *errx.Error {
	return ErrRegistry.New(CodeScheduleConflict)
}

func ErrScheduleExecutionFailed() *errx.Error {
	return ErrRegistry.New(CodeScheduleExecutionFailed)
}

func ErrScheduleNotActive() *errx.Error {
	return ErrRegistry.New(CodeScheduleNotActive)
}

func ErrTooManySchedules() *errx.Error {
	return ErrRegistry.New(CodeTooManySchedules)
}
package engine

import (
	"encoding/json"
	"fmt"

	"github.com/Abraxas-365/craftable/ai/llm"
	"github.com/Abraxas-365/craftable/ai/providers/aiopenai"
	"github.com/Abraxas-365/craftable/ptrx"
)

// ============================================================================
// Node Config Interface
// ============================================================================

// NodeConfig interface that all node configs should implement
type NodeConfig interface {
	Validate() error
	GetType() NodeType
	GetTimeout() int
}

// ============================================================================
// AI Agent Config
// ============================================================================

type AIAgentConfig struct {
	Provider           string         `json:"provider"`
	Model              string         `json:"model"`
	SystemPrompt       string         `json:"system_prompt"`
	Prompt             string         `json:"prompt,omitempty"`
	Temperature        *float32       `json:"temperature,omitempty"`
	MaxTokens          *int           `json:"max_tokens,omitempty"`
	Timeout            *int           `json:"timeout,omitempty"`
	UseMemory          bool           `json:"use_memory,omitempty"`
	Tools              []string       `json:"tools,omitempty"`
	MaxAutoIterations  *int           `json:"max_auto_iterations,omitempty"`
	MaxTotalIterations *int           `json:"max_total_iterations,omitempty"`
	Metadata           map[string]any `json:"metadata,omitempty"`
}

// Validate validates the AI agent configuration
func (c AIAgentConfig) Validate() error {
	if c.Provider == "" {
		return ErrInvalidWorkflowNode().WithDetail("reason", "provider is required")
	}
	if c.Model == "" {
		return ErrInvalidWorkflowNode().WithDetail("reason", "model is required")
	}
	if c.SystemPrompt == "" {
		return ErrInvalidWorkflowNode().WithDetail("reason", "system_prompt is required")
	}

	// Validate temperature range
	if c.Temperature != nil && (*c.Temperature < 0 || *c.Temperature > 2) {
		return ErrInvalidWorkflowNode().WithDetail("reason", "temperature must be between 0 and 2")
	}

	// Validate max tokens
	if c.MaxTokens != nil && *c.MaxTokens <= 0 {
		return ErrInvalidWorkflowNode().WithDetail("reason", "max_tokens must be positive")
	}

	return nil
}

func (c AIAgentConfig) GetType() NodeType {
	return NodeTypeAIAgent
}

func (c AIAgentConfig) GetTimeout() int {
	if c.Timeout != nil && *c.Timeout > 0 {
		return *c.Timeout
	}
	return 60 // AI agents need more time
}

// GetLLMClient creates an LLM client based on provider
func (c AIAgentConfig) GetLLMClient() llm.Client {
	// TODO: Support multiple providers
	switch c.Provider {
	case "openai":
		provider := aiopenai.NewOpenAIProvider("") // API key from env
		return *llm.NewClient(provider)
	// case "anthropic":
	//     provider := anthropic.NewAnthropicProvider("")
	//     return *llm.NewClient(provider)
	default:
		// Default to OpenAI
		provider := aiopenai.NewOpenAIProvider("")
		return *llm.NewClient(provider)
	}
}

// GetLLMOptions returns LLM options for the client
func (c AIAgentConfig) GetLLMOptions() []llm.Option {
	return []llm.Option{
		llm.WithModel(c.Model),
		llm.WithTemperature(ptrx.Float32ValueOr(c.Temperature, 0.7)),
		llm.WithMaxTokens(ptrx.IntValueOr(c.MaxTokens, 1000)),
	}
}

// GetMaxAutoIterations returns max auto iterations with default
func (c AIAgentConfig) GetMaxAutoIterations() int {
	if c.MaxAutoIterations != nil && *c.MaxAutoIterations > 0 {
		return *c.MaxAutoIterations
	}
	return 3 // Default
}

// GetMaxTotalIterations returns max total iterations with default
func (c AIAgentConfig) GetMaxTotalIterations() int {
	if c.MaxTotalIterations != nil && *c.MaxTotalIterations > 0 {
		return *c.MaxTotalIterations
	}
	return 10 // Default
}

// ============================================================================
// HTTP Config
// ============================================================================

type HTTPConfig struct {
	Method         string            `json:"method"` // GET, POST, PUT, etc.
	URL            string            `json:"url"`    // Request URL
	Headers        map[string]string `json:"headers,omitempty"`
	Body           map[string]any    `json:"body,omitempty"`
	Timeout        *int              `json:"timeout,omitempty"`       // seconds
	SuccessCodes   []int             `json:"success_codes,omitempty"` // [200, 201, 204]
	RetryOnFailure bool              `json:"retry_on_failure,omitempty"`
	MaxRetries     *int              `json:"max_retries,omitempty"`
	Metadata       map[string]any    `json:"metadata,omitempty"`
}

func (c HTTPConfig) Validate() error {
	if c.URL == "" {
		return ErrInvalidWorkflowNode().WithDetail("reason", "url is required")
	}

	// Validate HTTP method
	validMethods := []string{"GET", "POST", "PUT", "PATCH", "DELETE", "HEAD", "OPTIONS"}
	method := c.Method
	if method == "" {
		method = "GET" // Default
	}

	isValid := false
	for _, vm := range validMethods {
		if method == vm {
			isValid = true
			break
		}
	}
	if !isValid {
		return ErrInvalidWorkflowNode().WithDetail("reason", "invalid HTTP method: "+method)
	}

	return nil
}

func (c HTTPConfig) GetType() NodeType {
	return NodeTypeHTTP
}

func (c HTTPConfig) GetTimeout() int {
	if c.Timeout != nil && *c.Timeout > 0 {
		return *c.Timeout
	}
	return 30
}

func (c HTTPConfig) GetMethod() string {
	if c.Method == "" {
		return "GET"
	}
	return c.Method
}

func (c HTTPConfig) GetSuccessCodes() []int {
	if len(c.SuccessCodes) == 0 {
		return []int{200, 201, 202, 204}
	}
	return c.SuccessCodes
}

func (c HTTPConfig) GetMaxRetries() int {
	if c.MaxRetries != nil && *c.MaxRetries > 0 {
		return *c.MaxRetries
	}
	return 0 // No retries by default
}

// ============================================================================
// Switch Config
// ============================================================================

type SwitchConfig struct {
	Field    string         `json:"field"` // Field to evaluate
	Cases    map[string]any `json:"cases"` // case_value -> node_id
	Metadata map[string]any `json:"metadata,omitempty"`
}

func (c SwitchConfig) Validate() error {
	if c.Field == "" {
		return ErrInvalidWorkflowNode().WithDetail("reason", "field is required")
	}
	if len(c.Cases) == 0 {
		return ErrInvalidWorkflowNode().WithDetail("reason", "cases cannot be empty")
	}

	// Validate that all cases map to strings (node IDs)
	for key, value := range c.Cases {
		if _, ok := value.(string); !ok {
			return ErrInvalidWorkflowNode().WithDetail("reason", fmt.Sprintf("case '%s' must map to a node ID (string)", key))
		}
	}

	return nil
}

func (c SwitchConfig) GetType() NodeType {
	return NodeTypeSwitch
}

func (c SwitchConfig) GetTimeout() int {
	return 5 // Fast operation
}

// ============================================================================
// Transform Config
// ============================================================================

type TransformConfig struct {
	Mappings map[string]any `json:"mappings"` // target_key -> source_expression
	Metadata map[string]any `json:"metadata,omitempty"`
}

func (c TransformConfig) Validate() error {
	if len(c.Mappings) == 0 {
		return ErrInvalidWorkflowNode().WithDetail("reason", "mappings cannot be empty")
	}
	return nil
}

func (c TransformConfig) GetType() NodeType {
	return NodeTypeTransform
}

func (c TransformConfig) GetTimeout() int {
	return 5 // Fast operation
}

// ============================================================================
// Loop Config
// ============================================================================

type LoopConfig struct {
	IterateOver   string         `json:"iterate_over"`        // Collection to iterate
	ItemVar       string         `json:"item_var"`            // Variable name for item
	IndexVar      string         `json:"index_var,omitempty"` // Variable name for index
	BodyNode      string         `json:"body_node"`           // Node ID to execute for each item
	MaxIterations *int           `json:"max_iterations,omitempty"`
	Metadata      map[string]any `json:"metadata,omitempty"`
}

func (c LoopConfig) Validate() error {
	if c.IterateOver == "" {
		return ErrInvalidWorkflowNode().WithDetail("reason", "iterate_over is required")
	}
	if c.ItemVar == "" {
		return ErrInvalidWorkflowNode().WithDetail("reason", "item_var is required")
	}
	if c.BodyNode == "" {
		return ErrInvalidWorkflowNode().WithDetail("reason", "body_node is required")
	}

	// Validate max iterations
	if c.MaxIterations != nil && (*c.MaxIterations <= 0 || *c.MaxIterations > 10000) {
		return ErrInvalidWorkflowNode().WithDetail("reason", "max_iterations must be between 1 and 10000")
	}

	return nil
}

func (c LoopConfig) GetType() NodeType {
	return NodeTypeLoop
}

func (c LoopConfig) GetTimeout() int {
	return 300 // Loops can take time (5 minutes)
}

func (c LoopConfig) GetMaxIterations() int {
	if c.MaxIterations != nil && *c.MaxIterations > 0 {
		return *c.MaxIterations
	}
	return 1000 // Default
}

func (c LoopConfig) GetItemVar() string {
	if c.ItemVar == "" {
		return "item" // Default
	}
	return c.ItemVar
}

// ============================================================================
// Validate Config
// ============================================================================

type ValidateConfig struct {
	Schema      map[string]any `json:"schema"`                  // field -> validation_rule
	FailOnError bool           `json:"fail_on_error,omitempty"` // Stop workflow on validation failure
	Metadata    map[string]any `json:"metadata,omitempty"`
}

func (c ValidateConfig) Validate() error {
	if len(c.Schema) == 0 {
		return ErrInvalidWorkflowNode().WithDetail("reason", "schema cannot be empty")
	}

	// Validate that all schema values are strings (validation rules)
	for field, rule := range c.Schema {
		if _, ok := rule.(string); !ok {
			return ErrInvalidWorkflowNode().WithDetail("reason", fmt.Sprintf("validation rule for field '%s' must be a string", field))
		}
	}

	return nil
}

func (c ValidateConfig) GetType() NodeType {
	return NodeTypeValidate
}

func (c ValidateConfig) GetTimeout() int {
	return 5 // Fast operation
}

func (c ValidateConfig) ShouldFailOnError() bool {
	return c.FailOnError // Default is false (allow workflow to continue)
}

// ============================================================================
// Helper Functions for Config Extraction
// ============================================================================

// ExtractAIAgentConfig extracts and validates AI agent config from node config
func ExtractAIAgentConfig(config map[string]any) (*AIAgentConfig, error) {
	// Marshal and unmarshal to convert map to struct
	data, err := json.Marshal(config)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal config: %w", err)
	}

	var aiConfig AIAgentConfig
	if err := json.Unmarshal(data, &aiConfig); err != nil {
		return nil, fmt.Errorf("failed to unmarshal AI agent config: %w", err)
	}

	if err := aiConfig.Validate(); err != nil {
		return nil, err
	}

	return &aiConfig, nil
}

// ExtractHTTPConfig extracts and validates HTTP config
func ExtractHTTPConfig(config map[string]any) (*HTTPConfig, error) {
	data, err := json.Marshal(config)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal config: %w", err)
	}

	var httpConfig HTTPConfig
	if err := json.Unmarshal(data, &httpConfig); err != nil {
		return nil, fmt.Errorf("failed to unmarshal HTTP config: %w", err)
	}

	if err := httpConfig.Validate(); err != nil {
		return nil, err
	}

	return &httpConfig, nil
}

// ExtractSwitchConfig extracts and validates switch config
func ExtractSwitchConfig(config map[string]any) (*SwitchConfig, error) {
	data, err := json.Marshal(config)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal config: %w", err)
	}

	var switchConfig SwitchConfig
	if err := json.Unmarshal(data, &switchConfig); err != nil {
		return nil, fmt.Errorf("failed to unmarshal switch config: %w", err)
	}

	if err := switchConfig.Validate(); err != nil {
		return nil, err
	}

	return &switchConfig, nil
}

// ExtractTransformConfig extracts and validates transform config
func ExtractTransformConfig(config map[string]any) (*TransformConfig, error) {
	data, err := json.Marshal(config)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal config: %w", err)
	}

	var transformConfig TransformConfig
	if err := json.Unmarshal(data, &transformConfig); err != nil {
		return nil, fmt.Errorf("failed to unmarshal transform config: %w", err)
	}

	if err := transformConfig.Validate(); err != nil {
		return nil, err
	}

	return &transformConfig, nil
}

// ExtractLoopConfig extracts and validates loop config
func ExtractLoopConfig(config map[string]any) (*LoopConfig, error) {
	data, err := json.Marshal(config)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal config: %w", err)
	}

	var loopConfig LoopConfig
	if err := json.Unmarshal(data, &loopConfig); err != nil {
		return nil, fmt.Errorf("failed to unmarshal loop config: %w", err)
	}

	if err := loopConfig.Validate(); err != nil {
		return nil, err
	}

	return &loopConfig, nil
}

// ExtractValidateConfig extracts and validates validation config
func ExtractValidateConfig(config map[string]any) (*ValidateConfig, error) {
	data, err := json.Marshal(config)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal config: %w", err)
	}

	var validateConfig ValidateConfig
	if err := json.Unmarshal(data, &validateConfig); err != nil {
		return nil, fmt.Errorf("failed to unmarshal validate config: %w", err)
	}

	if err := validateConfig.Validate(); err != nil {
		return nil, err
	}

	return &validateConfig, nil
}
package workflowexec

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/Abraxas-365/craftable/errx"
	"github.com/Abraxas-365/relay/engine"
)

type DefaultWorkflowExecutor struct {
	nodeExecutors       map[engine.NodeType]engine.NodeExecutor
	expressionEvaluator engine.ExpressionEvaluator
}

var _ engine.WorkflowExecutor = (*DefaultWorkflowExecutor)(nil)

func NewDefaultWorkflowExecutor(
	expressionEvaluator engine.ExpressionEvaluator,
	nodeExecutors ...engine.NodeExecutor,
) *DefaultWorkflowExecutor {
	executor := &DefaultWorkflowExecutor{
		nodeExecutors:       make(map[engine.NodeType]engine.NodeExecutor),
		expressionEvaluator: expressionEvaluator,
	}

	for _, nodeExec := range nodeExecutors {
		executor.RegisterNodeExecutor(nodeExec)
	}

	return executor
}

func (e *DefaultWorkflowExecutor) RegisterNodeExecutor(executor engine.NodeExecutor) {
	// Register for all supported types
	for _, nodeType := range []engine.NodeType{
		engine.NodeTypeCondition,
		engine.NodeTypeAction,
		engine.NodeTypeDelay,
		engine.NodeTypeAIAgent,
		engine.NodeTypeSendMessage,
		engine.NodeTypeHTTP,
		engine.NodeTypeTransform,
		engine.NodeTypeSwitch,
		engine.NodeTypeLoop,
		engine.NodeTypeValidate,
	} {
		if executor.SupportsType(nodeType) {
			e.nodeExecutors[nodeType] = executor
			log.Printf("‚úÖ Registered executor for node type: %s", nodeType)
		}
	}
}

// ============================================================================
// Execute - Main workflow execution
// ============================================================================

func (e *DefaultWorkflowExecutor) Execute(
	ctx context.Context,
	workflow engine.Workflow,
	input engine.WorkflowInput,
) (*engine.ExecutionResult, error) {
	log.Printf("üöÄ Starting workflow execution: %s", workflow.Name)

	startTime := time.Now()
	result := &engine.ExecutionResult{
		Success:       true,
		Output:        make(map[string]any),
		ExecutedNodes: []engine.NodeResult{},
	}

	if err := e.ValidateWorkflow(ctx, workflow); err != nil {
		return nil, errx.Wrap(err, "workflow validation failed", errx.TypeValidation)
	}

	// Prepare initial context from input
	nodeContext := e.prepareInitialContext(input)
	log.Printf("üì¶ Initial context keys: %v", getMapKeys(nodeContext))

	// Start from first node
	currentNodeID := ""
	if len(workflow.Nodes) > 0 {
		currentNodeID = workflow.Nodes[0].ID
	}

	visitedNodes := make(map[string]bool)
	maxNodes := len(workflow.Nodes) * 2

	for currentNodeID != "" && len(result.ExecutedNodes) < maxNodes {
		if visitedNodes[currentNodeID] {
			return nil, engine.ErrCyclicWorkflow().
				WithDetail("node_id", currentNodeID).
				WithDetail("workflow_id", workflow.ID.String())
		}
		visitedNodes[currentNodeID] = true

		node := workflow.GetNodeByID(currentNodeID)
		if node == nil {
			return nil, engine.ErrNodeNotFound().WithDetail("node_id", currentNodeID)
		}

		log.Printf("\nüîπ Processing node: %s (ID: %s, Type: %s)", node.Name, node.ID, node.Type)
		log.Printf("   üìã Node context keys before eval: %v", getMapKeys(nodeContext))
		log.Printf("   ‚öôÔ∏è  Node config before eval: %+v", node.Config)

		// Evaluate expressions in config
		evaluatedConfig, err := e.evaluateNodeConfig(ctx, node.Config, nodeContext)
		if err != nil {
			log.Printf("‚ùå Expression evaluation failed for node %s: %v", node.Name, err)
			log.Printf("   üìã Available context keys: %v", getMapKeys(nodeContext))
			log.Printf("   üîç Context dump: %+v", nodeContext)

			nodeResult := &engine.NodeResult{
				NodeID:    node.ID,
				NodeName:  node.Name,
				Success:   false,
				Error:     fmt.Sprintf("expression evaluation failed: %v", err),
				Timestamp: time.Now(),
			}
			result.ExecutedNodes = append(result.ExecutedNodes, *nodeResult)
			result.Success = false
			result.ErrorMessage = nodeResult.Error
			break
		}

		log.Printf("   ‚úÖ Config after eval: %+v", evaluatedConfig)

		nodeForExecution := *node
		nodeForExecution.Config = evaluatedConfig

		// Execute node
		nodeResult, err := e.executeNodeInternal(ctx, nodeForExecution, nodeContext, result)
		if err != nil && nodeResult == nil {
			nodeResult = &engine.NodeResult{
				NodeID: node.ID, NodeName: node.Name, Success: false,
				Error: err.Error(), Timestamp: time.Now(),
			}
		}

		log.Printf("   üìä Node result: success=%v, error=%s", nodeResult.Success, nodeResult.Error)
		log.Printf("   üì§ Node output keys: %v", getMapKeys(nodeResult.Output))

		result.ExecutedNodes = append(result.ExecutedNodes, *nodeResult)

		// Check for workflow pause (async delay)
		if paused, ok := nodeResult.Output["__workflow_paused"].(bool); ok && paused {
			log.Printf("‚è∏Ô∏è  Workflow paused for async delay")
			result.Success = true
			return result, nil
		}

		if !nodeResult.Success {
			log.Printf("‚ùå Node %s failed with error: %s", node.Name, nodeResult.Error)
			result.Success = false
			result.Error = fmt.Errorf("node %s failed: %s", node.Name, nodeResult.Error)
			result.ErrorMessage = nodeResult.Error

			if node.OnFailure != "" {
				log.Printf("   ‚Ü™Ô∏è  Jumping to failure node: %s", node.OnFailure)
				currentNodeID = node.OnFailure
				continue
			}
			log.Printf("   üõë No failure handler, stopping workflow")
			break
		}

		// Update context with node output
		if nodeResult.Output != nil {
			nodeContext[node.ID] = map[string]any{
				"output":      nodeResult.Output,
				"success":     nodeResult.Success,
				"duration_ms": nodeResult.Duration,
			}

			log.Printf("   üíæ Stored node output in context with key: %s", node.ID)
			log.Printf("   üì¶ Updated context keys: %v", getMapKeys(nodeContext))

			for key, value := range nodeResult.Output {
				result.Output[key] = value
			}
		}

		// Determine next node
		if nextNodeOverride, ok := nodeContext["__next_node"].(string); ok {
			log.Printf("   ‚û°Ô∏è  Next node (override): %s", nextNodeOverride)
			currentNodeID = nextNodeOverride
			delete(nodeContext, "__next_node")
		} else if node.OnSuccess != "" {
			log.Printf("   ‚û°Ô∏è  Next node (on_success): %s", node.OnSuccess)
			currentNodeID = node.OnSuccess
		} else {
			log.Printf("   üèÅ No next node, workflow complete")
			currentNodeID = ""
		}
	}

	duration := time.Since(startTime)
	log.Printf("‚úÖ Workflow execution completed: %s in %v (success=%v)", workflow.Name, duration, result.Success)

	return result, nil
}

// ============================================================================
// ResumeFromNode - Resume workflow after delay
// ============================================================================

func (e *DefaultWorkflowExecutor) ResumeFromNode(
	ctx context.Context,
	workflow engine.Workflow,
	input engine.WorkflowInput,
	startNodeID string,
	savedNodeContext map[string]any,
) (*engine.ExecutionResult, error) {
	log.Printf("üîÑ Resuming workflow: %s from node: %s", workflow.Name, startNodeID)

	startTime := time.Now()
	result := &engine.ExecutionResult{
		Success:       true,
		Output:        make(map[string]any),
		ExecutedNodes: []engine.NodeResult{},
	}

	if err := e.ValidateWorkflow(ctx, workflow); err != nil {
		return nil, errx.Wrap(err, "workflow validation failed", errx.TypeValidation)
	}

	startNode := workflow.GetNodeByID(startNodeID)
	if startNode == nil {
		return nil, engine.ErrNodeNotFound().WithDetail("node_id", startNodeID)
	}

	// Use saved context or create new
	nodeContext := savedNodeContext
	if nodeContext == nil {
		nodeContext = e.prepareInitialContext(input)
	}

	// Ensure trigger data is available
	if _, ok := nodeContext["trigger"]; !ok {
		nodeContext["trigger"] = input.TriggerData
	}

	currentNodeID := startNodeID
	visitedNodes := make(map[string]bool)
	maxNodes := len(workflow.Nodes) * 2

	for currentNodeID != "" && len(result.ExecutedNodes) < maxNodes {
		if visitedNodes[currentNodeID] {
			return nil, engine.ErrCyclicWorkflow().
				WithDetail("node_id", currentNodeID).
				WithDetail("workflow_id", workflow.ID.String())
		}
		visitedNodes[currentNodeID] = true

		node := workflow.GetNodeByID(currentNodeID)
		if node == nil {
			return nil, engine.ErrNodeNotFound().WithDetail("node_id", currentNodeID)
		}

		evaluatedConfig, err := e.evaluateNodeConfig(ctx, node.Config, nodeContext)
		if err != nil {
			nodeResult := &engine.NodeResult{
				NodeID: node.ID, NodeName: node.Name, Success: false,
				Error: fmt.Sprintf("expression evaluation failed: %v", err), Timestamp: time.Now(),
			}
			result.ExecutedNodes = append(result.ExecutedNodes, *nodeResult)
			result.Success = false
			result.ErrorMessage = nodeResult.Error
			break
		}

		nodeForExecution := *node
		nodeForExecution.Config = evaluatedConfig

		nodeResult, err := e.executeNodeInternal(ctx, nodeForExecution, nodeContext, result)
		if err != nil && nodeResult == nil {
			nodeResult = &engine.NodeResult{
				NodeID: node.ID, NodeName: node.Name, Success: false,
				Error: err.Error(), Timestamp: time.Now(),
			}
		}

		result.ExecutedNodes = append(result.ExecutedNodes, *nodeResult)

		if !nodeResult.Success {
			result.Success = false
			result.Error = fmt.Errorf("node %s failed: %s", node.Name, nodeResult.Error)
			result.ErrorMessage = nodeResult.Error
			if node.OnFailure != "" {
				currentNodeID = node.OnFailure
				continue
			}
			break
		}

		if nodeResult.Output != nil {
			nodeContext[node.ID] = map[string]any{
				"output":      nodeResult.Output,
				"success":     nodeResult.Success,
				"duration_ms": nodeResult.Duration,
			}

			for key, value := range nodeResult.Output {
				result.Output[key] = value
			}
		}

		if nextNodeOverride, ok := nodeContext["__next_node"].(string); ok {
			currentNodeID = nextNodeOverride
			delete(nodeContext, "__next_node")
		} else if node.OnSuccess != "" {
			currentNodeID = node.OnSuccess
		} else {
			currentNodeID = ""
		}
	}

	duration := time.Since(startTime)
	log.Printf("‚úÖ Workflow resume completed: %s in %v", workflow.Name, duration)

	return result, nil
}

// ============================================================================
// Internal Execution
// ============================================================================

func (e *DefaultWorkflowExecutor) executeNodeInternal(
	ctx context.Context,
	node engine.WorkflowNode,
	nodeContext map[string]any,
	workflowResult *engine.ExecutionResult,
) (*engine.NodeResult, error) {
	log.Printf("‚ö° Executing node: %s (type: %s)", node.Name, node.Type)
	startTime := time.Now()

	if node.Timeout != nil && *node.Timeout > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(ctx, time.Duration(*node.Timeout)*time.Second)
		defer cancel()
	}

	nodeResult := &engine.NodeResult{
		NodeID:    node.ID,
		NodeName:  node.Name,
		Success:   true,
		Output:    make(map[string]any),
		Timestamp: startTime,
	}

	var err error

	// Check for registered executor
	if executor, ok := e.nodeExecutors[node.Type]; ok {
		input := nodeContext // Pass entire context as input
		nodeResult, err = executor.Execute(ctx, node, input)

		if nodeResult.NodeID == "" {
			nodeResult.NodeID = node.ID
		}
		if nodeResult.NodeName == "" {
			nodeResult.NodeName = node.Name
		}

		if err == nil && nodeResult.Output != nil {
			for key, value := range nodeResult.Output {
				workflowResult.Output[key] = value
			}
		}
	} else {
		log.Printf("‚ùå No executor found for node type: %s", node.Type)
		err = engine.ErrInvalidWorkflowNode().
			WithDetail("node_type", string(node.Type)).
			WithDetail("reason", "no executor found for node type")
	}

	nodeResult.Duration = time.Since(startTime).Milliseconds()

	if err != nil {
		nodeResult.Success = false
		nodeResult.Error = err.Error()
		return nodeResult, err
	}

	return nodeResult, nil
}

// ============================================================================
// Helper Functions
// ============================================================================

func (e *DefaultWorkflowExecutor) prepareInitialContext(input engine.WorkflowInput) map[string]any {
	context := make(map[string]any)

	// Add trigger data
	context["trigger"] = input.TriggerData
	context["tenant_id"] = input.TenantID.String()

	// Add metadata
	if input.Metadata != nil {
		for key, value := range input.Metadata {
			context[key] = value
		}
	}

	return context
}

func (e *DefaultWorkflowExecutor) evaluateNodeConfig(
	ctx context.Context,
	config map[string]any,
	nodeContext map[string]any,
) (map[string]any, error) {
	evaluatedData, err := e.expressionEvaluator.Evaluate(ctx, config, nodeContext)
	if err != nil {
		return nil, err
	}

	evaluatedConfig, ok := evaluatedData.(map[string]any)
	if !ok {
		return nil, fmt.Errorf("expression evaluation did not return valid config map")
	}

	return evaluatedConfig, nil
}

// getMapKeys returns all keys from a map for debugging
func getMapKeys(m map[string]any) []string {
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	return keys
}

// ============================================================================
// Validation
// ============================================================================

func (e *DefaultWorkflowExecutor) ValidateWorkflow(ctx context.Context, workflow engine.Workflow) error {
	if !workflow.IsValid() {
		return engine.ErrInvalidWorkflowConfig().WithDetail("reason", "workflow is not valid")
	}

	if len(workflow.Nodes) == 0 {
		return engine.ErrInvalidWorkflowConfig().WithDetail("reason", "workflow has no nodes")
	}

	nodeIDs := make(map[string]bool)
	for _, node := range workflow.Nodes {
		if node.ID == "" {
			return engine.ErrInvalidWorkflowNode().WithDetail("reason", "node has no ID")
		}
		if nodeIDs[node.ID] {
			return engine.ErrInvalidWorkflowNode().
				WithDetail("node_id", node.ID).
				WithDetail("reason", "duplicate node ID")
		}
		nodeIDs[node.ID] = true

		if executor, ok := e.nodeExecutors[node.Type]; ok {
			if err := executor.ValidateConfig(node.Config); err != nil {
				return errx.Wrap(err, "node config validation failed", errx.TypeValidation).
					WithDetail("node_id", node.ID).
					WithDetail("node_name", node.Name)
			}
		}
	}

	for _, node := range workflow.Nodes {
		if node.OnSuccess != "" && !nodeIDs[node.OnSuccess] {
			return engine.ErrInvalidWorkflowNode().
				WithDetail("node_id", node.ID).
				WithDetail("on_success", node.OnSuccess).
				WithDetail("reason", "on_success references non-existent node")
		}
		if node.OnFailure != "" && !nodeIDs[node.OnFailure] {
			return engine.ErrInvalidWorkflowNode().
				WithDetail("node_id", node.ID).
				WithDetail("on_failure", node.OnFailure).
				WithDetail("reason", "on_failure references non-existent node")
		}
	}

	return nil
}

// Utility functions
func compareNumeric(a, b any, operator string) bool {
	aFloat, aOk := toFloat64(a)
	bFloat, bOk := toFloat64(b)

	if !aOk || !bOk {
		return false
	}

	switch operator {
	case "gt":
		return aFloat > bFloat
	case "gte":
		return aFloat >= bFloat
	case "lt":
		return aFloat < bFloat
	case "lte":
		return aFloat <= bFloat
	default:
		return false
	}
}

func toFloat64(v any) (float64, bool) {
	switch val := v.(type) {
	case float64:
		return val, true
	case float32:
		return float64(val), true
	case int:
		return float64(val), true
	case int64:
		return float64(val), true
	case int32:
		return float64(val), true
	case string:
		var f float64
		_, err := fmt.Sscanf(val, "%f", &f)
		return f, err == nil
	default:
		return 0, false
	}
}
